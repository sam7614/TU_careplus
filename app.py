import streamlit as st
import pandas as pd
import numpy as np
import os
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from typing import Dict, Any, List, Tuple, Optional
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from dataclasses import dataclass
from lifelines import KaplanMeierFitter
from lifelines.statistics import logrank_test
import warnings
warnings.filterwarnings('ignore')

from config import (
    CRISIS_CRITERIA, SURVIVAL_CRITERIA, UI_CONFIG, DATA_CONFIG, 
    MESSAGES, RISK_FACTORS, RISK_LEVELS, DEVELOPER_INFO
)

# Data Models for Survival Analysis
@dataclass
class KMCurve:
    """Kaplan-Meier curve data structure"""
    time_points: List[float]        # ì‹œê°„ í¬ì¸íŠ¸ë“¤
    survival_probs: List[float]     # ìƒì¡´ í™•ë¥ ë“¤
    confidence_lower: List[float]   # 95% ì‹ ë¢°êµ¬ê°„ í•˜í•œ
    confidence_upper: List[float]   # 95% ì‹ ë¢°êµ¬ê°„ ìƒí•œ
    group_name: str                 # ê·¸ë£¹ëª… (í•™ê³¼/í•™ë…„)
    median_survival_time: Optional[float]  # ì¤‘ì•™ìƒì¡´ì‹œê°„
    
@dataclass
class SurvivalAnalysisResult:
    """Complete survival analysis results"""
    overall_curve: KMCurve          # ì „ì²´ ìƒì¡´ê³¡ì„ 
    department_curves: List[KMCurve] # í•™ê³¼ë³„ ìƒì¡´ê³¡ì„ ë“¤
    grade_curves: List[KMCurve]     # í•™ë…„ë³„ ìƒì¡´ê³¡ì„ ë“¤
    log_rank_p_value: Optional[float]  # ë¡œê·¸ë­í¬ ê²€ì • pê°’

# Page configuration
st.set_page_config(
    page_title=UI_CONFIG['page_title'],
    page_icon="ğŸ“",
    layout="wide"
)

def load_student_data(file_path: str) -> pd.DataFrame:
    """
    Load student data from CSV file with proper encoding handling
    """
    if not os.path.exists(file_path):
        st.error(MESSAGES['error']['file_not_found'].format(file_path))
        st.info(MESSAGES['info']['file_help'])
        return pd.DataFrame()
    
    try:
        # Try different encodings for Korean text
        df = None
        
        for encoding in DATA_CONFIG['encodings']:
            try:
                df = pd.read_csv(file_path, encoding=encoding)
                break
            except UnicodeDecodeError:
                continue
        
        if df is None:
            st.error(MESSAGES['error']['encoding_error'])
            return pd.DataFrame()
        
        # If columns don't match, assume the file has the structure we saw
        expected_columns = DATA_CONFIG['required_columns']
        if len(df.columns) >= len(expected_columns):
            df.columns = expected_columns
        else:
            st.error(MESSAGES['error']['column_mismatch'].format(len(expected_columns), len(df.columns)))
            return pd.DataFrame()
        
        # Convert numeric columns
        for col in DATA_CONFIG['numeric_columns']:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        
        return df
        
    except Exception as e:
        st.error(MESSAGES['error']['general_error'].format(str(e)))
        return pd.DataFrame()

def calculate_survival_risk_score(df: pd.DataFrame) -> pd.DataFrame:
    """
    Calculate survival-based risk scores for students using weighted features
    """
    if df.empty:
        return df
    
    df_risk = df.copy()
    
    # Normalize features to 0-1 scale for risk calculation
    # GPA risk (lower GPA = higher risk)
    df_risk['gpa_risk'] = 1 - (df_risk['ì§ì „í•™ê¸°_í‰ì '] / 4.5)  # Assuming 4.5 scale
    df_risk['gpa_risk'] = np.clip(df_risk['gpa_risk'], 0, 1)
    
    # Attendance risk (lower attendance = higher risk)
    df_risk['attendance_risk'] = 1 - (df_risk['í‰ê· _ì¶œì„ë¥ '] / 100)
    df_risk['attendance_risk'] = np.clip(df_risk['attendance_risk'], 0, 1)
    
    # Tuition risk (unpaid = high risk)
    tuition_risk_map = {'ì™„ë‚©': 0.0, 'ë¶€ë¶„ë‚©': 0.6, 'ë¯¸ë‚©': 1.0}
    df_risk['tuition_risk'] = df_risk['ë“±ë¡ê¸ˆ_ë‚©ë¶€_ìƒíƒœ'].map(tuition_risk_map).fillna(0.5)
    
    # Counseling risk (fewer sessions = higher risk)
    max_counseling = df_risk['ìƒë‹´_ë°›ì€_íšŸìˆ˜'].max() if df_risk['ìƒë‹´_ë°›ì€_íšŸìˆ˜'].max() > 0 else 1
    df_risk['counseling_risk'] = 1 - (df_risk['ìƒë‹´_ë°›ì€_íšŸìˆ˜'] / max_counseling)
    df_risk['counseling_risk'] = np.clip(df_risk['counseling_risk'], 0, 1)
    
    # Scholarship risk (no scholarship = higher risk)
    df_risk['scholarship_risk'] = df_risk['ì¥í•™ê¸ˆ_ì‹ ì²­'].map({'O': 0.0, 'X': 1.0}).fillna(0.5)
    
    # Library usage risk (less usage = higher risk)
    max_library = df_risk['ë„ì„œê´€_ì´ìš©_íšŸìˆ˜'].max() if df_risk['ë„ì„œê´€_ì´ìš©_íšŸìˆ˜'].max() > 0 else 1
    df_risk['library_risk'] = 1 - (df_risk['ë„ì„œê´€_ì´ìš©_íšŸìˆ˜'] / max_library)
    df_risk['library_risk'] = np.clip(df_risk['library_risk'], 0, 1)
    
    # Double major bonus (application = lower risk)
    if 'ë‹¤ì „ê³µì‹ ì²­' in df_risk.columns:
        df_risk['double_major_bonus'] = df_risk['ë‹¤ì „ê³µì‹ ì²­'].map({'O': -0.1, 'X': 0.0}).fillna(0.0)  # ì‹ ì²­ì‹œ ë³´ë„ˆìŠ¤
    else:
        df_risk['double_major_bonus'] = 0.0
    
    # Module bonus (application = lower risk)
    if 'ëª¨ë“ˆì‹ ì²­' in df_risk.columns:
        df_risk['module_bonus'] = df_risk['ëª¨ë“ˆì‹ ì²­'].map({'O': -0.1, 'X': 0.0}).fillna(0.0)  # ì‹ ì²­ì‹œ ë³´ë„ˆìŠ¤
    else:
        df_risk['module_bonus'] = 0.0
    
    # Extracurricular bonus (more activities = lower risk)
    if 'ë¹„êµê³¼ì°¸ì—¬íšŸìˆ˜' in df_risk.columns:
        max_extracurricular = df_risk['ë¹„êµê³¼ì°¸ì—¬íšŸìˆ˜'].max() if df_risk['ë¹„êµê³¼ì°¸ì—¬íšŸìˆ˜'].max() > 0 else 1
        # ì •ê·œí™”ëœ ì°¸ì—¬ë„ë¥¼ ë³´ë„ˆìŠ¤ë¡œ ë³€í™˜ (0~1 ë²”ìœ„ë¥¼ -0.2~0 ë²”ìœ„ë¡œ)
        normalized_participation = df_risk['ë¹„êµê³¼ì°¸ì—¬íšŸìˆ˜'] / max_extracurricular
        df_risk['extracurricular_bonus'] = -(normalized_participation * 0.2)  # ìŒìˆ˜ ë³´ë„ˆìŠ¤ (ìµœëŒ€ -0.2)
        df_risk['extracurricular_bonus'] = np.clip(df_risk['extracurricular_bonus'], -0.2, 0)
    else:
        df_risk['extracurricular_bonus'] = 0.0
    
    # Calculate weighted risk score
    weights = SURVIVAL_CRITERIA['weights']
    df_risk['ìœ„í—˜_ì ìˆ˜'] = (
        df_risk['gpa_risk'] * weights['gpa'] +
        df_risk['attendance_risk'] * weights['attendance'] +
        df_risk['tuition_risk'] * weights['tuition'] +
        df_risk['counseling_risk'] * weights['counseling'] +
        df_risk['scholarship_risk'] * weights['scholarship'] +
        df_risk['library_risk'] * weights['library'] +
        df_risk['double_major_bonus'] * weights['double_major'] +  # ë³´ë„ˆìŠ¤ (ìŒìˆ˜ê°’)
        df_risk['module_bonus'] * weights['module'] +  # ë³´ë„ˆìŠ¤ (ìŒìˆ˜ê°’)
        df_risk['extracurricular_bonus'] * weights['extracurricular']  # ë³´ë„ˆìŠ¤ (ìŒìˆ˜ê°’)
    )
    
    # Classify risk levels
    def classify_risk(score):
        if score >= SURVIVAL_CRITERIA['high_risk_threshold']:
            return 'high'
        elif score >= SURVIVAL_CRITERIA['medium_risk_threshold']:
            return 'medium'
        elif score >= SURVIVAL_CRITERIA['low_risk_threshold']:
            return 'low'
        else:
            return 'safe'
    
    df_risk['ìœ„í—˜_ë ˆë²¨'] = df_risk['ìœ„í—˜_ì ìˆ˜'].apply(classify_risk)
    
    # Calculate detailed risk factors
    df_risk['ìœ„ê¸°_ìš”ì¸'] = df_risk.apply(calculate_detailed_risk_factors, axis=1)
    
    return df_risk

def calculate_detailed_risk_factors(row: pd.Series) -> str:
    """
    Calculate detailed risk factors for a student based on survival analysis
    """
    factors = []
    
    # Check each risk factor
    if row['gpa_risk'] > 0.5:
        factors.append(RISK_FACTORS['gpa'].format(row['ì§ì „í•™ê¸°_í‰ì ']))
    
    if row['attendance_risk'] > 0.3:
        factors.append(RISK_FACTORS['attendance'].format(row['í‰ê· _ì¶œì„ë¥ ']))
    
    if row['tuition_risk'] > 0.5:
        if row['ë“±ë¡ê¸ˆ_ë‚©ë¶€_ìƒíƒœ'] == 'ë¯¸ë‚©':
            factors.append(RISK_FACTORS['tuition'])
        elif row['ë“±ë¡ê¸ˆ_ë‚©ë¶€_ìƒíƒœ'] == 'ë¶€ë¶„ë‚©':
            factors.append(RISK_FACTORS['partial_tuition'])
    
    if row['counseling_risk'] > 0.7:
        factors.append(RISK_FACTORS['counseling'].format(row['ìƒë‹´_ë°›ì€_íšŸìˆ˜']))
    
    if row['scholarship_risk'] > 0.5:
        factors.append(RISK_FACTORS['scholarship'])
    
    if row['library_risk'] > 0.8:
        factors.append(RISK_FACTORS['library'].format(row['ë„ì„œê´€_ì´ìš©_íšŸìˆ˜']))
    
    # Check bonus factors (positive factors that reduce risk)
    # Note: ë‹¤ì „ê³µì‹ ì²­ê³¼ ëª¨ë“ˆì‹ ì²­ì€ ìœ„í—˜ ìš”ì¸ì´ ì•„ë‹ˆë¼ ë³´í˜¸ ìš”ì¸ì´ë¯€ë¡œ 
    # ìœ„í—˜ ìš”ì¸ ëª©ë¡ì— í¬í•¨í•˜ì§€ ì•ŠìŒ
    
    # ë¹„êµê³¼ì°¸ì—¬íšŸìˆ˜ë„ ì´ì œ ë³´í˜¸ìš”ì¸ì´ë¯€ë¡œ ìœ„í—˜ìš”ì¸ ëª©ë¡ì— í¬í•¨í•˜ì§€ ì•ŠìŒ
    
    return " | ".join(factors) if factors else "ìœ„í—˜ ìš”ì¸ ì—†ìŒ"

def get_median_survival_time(kmf: KaplanMeierFitter) -> Optional[float]:
    """
    Calculate median survival time from Kaplan-Meier fitter
    ì¤‘ì•™ìƒì¡´ì‹œê°„ ê³„ì‚° í•¨ìˆ˜
    
    Args:
        kmf: Fitted KaplanMeierFitter object
        
    Returns:
        Median survival time or None if not reached
    """
    try:
        median_time = kmf.median_survival_time_
        return float(median_time) if not pd.isna(median_time) else None
    except Exception:
        return None

def calculate_confidence_intervals(kmf: KaplanMeierFitter, confidence_level: float = 0.95) -> Tuple[List[float], List[float]]:
    """
    Calculate confidence intervals for survival probabilities
    95% ì‹ ë¢°êµ¬ê°„ ê³„ì‚° í•¨ìˆ˜
    
    Args:
        kmf: Fitted KaplanMeierFitter object
        confidence_level: Confidence level (default 0.95 for 95% CI)
        
    Returns:
        Tuple of (lower_bounds, upper_bounds) lists
    """
    try:
        # Get confidence intervals from the fitter
        ci = kmf.confidence_interval_survival_function_
        lower_bounds = ci.iloc[:, 0].tolist()  # Lower bound
        upper_bounds = ci.iloc[:, 1].tolist()  # Upper bound
        return lower_bounds, upper_bounds
    except Exception:
        # Return empty lists if calculation fails
        n_points = len(kmf.survival_function_)
        return [0.0] * n_points, [1.0] * n_points

def perform_log_rank_test(df: pd.DataFrame, duration_col: str, event_col: str, group_col: str) -> Optional[float]:
    """
    Perform log-rank test to compare survival curves between groups
    ë¡œê·¸ë­í¬ ê²€ì • ìˆ˜í–‰ í•¨ìˆ˜
    
    Args:
        df: DataFrame with survival data
        duration_col: Column name for duration/time
        event_col: Column name for event indicator (1=event, 0=censored)
        group_col: Column name for grouping variable
        
    Returns:
        p-value from log-rank test or None if test fails
    """
    try:
        # Get unique groups
        groups = df[group_col].unique()
        if len(groups) < 2:
            return None
            
        # Prepare data for first two groups (can be extended for multiple groups)
        group1_data = df[df[group_col] == groups[0]]
        group2_data = df[df[group_col] == groups[1]]
        
        # Perform log-rank test
        results = logrank_test(
            group1_data[duration_col], group2_data[duration_col],
            group1_data[event_col], group2_data[event_col]
        )
        
        return float(results.p_value)
    except Exception:
        return None

def calculate_kaplan_meier_curve(df: pd.DataFrame, duration_col: str, event_col: str, 
                                group_by: Optional[str] = None, group_value: Optional[str] = None) -> Optional[KMCurve]:
    """
    Calculate Kaplan-Meier survival curve for given data
    ì¹´í”Œë€-ë§ˆì´ì–´ ê³¡ì„  ê³„ì‚° í•¨ìˆ˜
    
    Args:
        df: DataFrame with survival data
        duration_col: Column name for duration/time
        event_col: Column name for event indicator
        group_by: Optional column name for grouping
        group_value: Specific group value to filter by
        
    Returns:
        KMCurve object with survival analysis results
    """
    try:
        # Filter data if grouping is specified
        if group_by and group_value:
            filtered_df = df[df[group_by] == group_value].copy()
            group_name = f"{group_by}: {group_value}"
        else:
            filtered_df = df.copy()
            group_name = "ì „ì²´"
            
        if filtered_df.empty:
            return None
            
        # Initialize Kaplan-Meier fitter
        kmf = KaplanMeierFitter()
        
        # Fit the model
        kmf.fit(
            durations=filtered_df[duration_col],
            event_observed=filtered_df[event_col],
            label=group_name
        )
        
        # Extract survival function data
        survival_function = kmf.survival_function_
        time_points = survival_function.index.tolist()
        survival_probs = survival_function.iloc[:, 0].tolist()
        
        # Calculate confidence intervals
        lower_bounds, upper_bounds = calculate_confidence_intervals(kmf)
        
        # Calculate median survival time
        median_time = get_median_survival_time(kmf)
        
        return KMCurve(
            time_points=time_points,
            survival_probs=survival_probs,
            confidence_lower=lower_bounds,
            confidence_upper=upper_bounds,
            group_name=group_name,
            median_survival_time=median_time
        )
        
    except Exception as e:
        st.error(f"ìƒì¡´ê³¡ì„  ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def calculate_survival_statistics(curves: List[KMCurve]) -> Dict[str, Any]:
    """
    Calculate summary statistics from survival curves
    ìƒì¡´ë¶„ì„ í†µê³„ ê³„ì‚° í•¨ìˆ˜
    
    Args:
        curves: List of KMCurve objects
        
    Returns:
        Dictionary with survival statistics
    """
    if not curves:
        return {}
        
    stats = {}
    
    for curve in curves:
        if curve:
            stats[curve.group_name] = {
                'median_survival_time': curve.median_survival_time,
                'survival_at_1_year': None,
                'survival_at_2_years': None,
                'confidence_interval_width': None
            }
            
            # Calculate survival probabilities at specific time points
            if curve.time_points and curve.survival_probs:
                # Find survival probability at 1 year (12 months)
                time_1_year = 12
                idx_1_year = None
                for i, time_point in enumerate(curve.time_points):
                    if time_point >= time_1_year:
                        idx_1_year = i
                        break
                
                if idx_1_year is not None:
                    stats[curve.group_name]['survival_at_1_year'] = curve.survival_probs[idx_1_year]
                
                # Find survival probability at 2 years (24 months)
                time_2_years = 24
                idx_2_years = None
                for i, time_point in enumerate(curve.time_points):
                    if time_point >= time_2_years:
                        idx_2_years = i
                        break
                
                if idx_2_years is not None:
                    stats[curve.group_name]['survival_at_2_years'] = curve.survival_probs[idx_2_years]
                
                # Calculate average confidence interval width
                if curve.confidence_lower and curve.confidence_upper:
                    ci_widths = [upper - lower for lower, upper in 
                               zip(curve.confidence_lower, curve.confidence_upper)]
                    stats[curve.group_name]['confidence_interval_width'] = np.mean(ci_widths)
    
    return stats

def calculate_summary_metrics(df: pd.DataFrame) -> Dict[str, Any]:
    """
    Calculate summary metrics for the survival analysis dashboard
    """
    if df.empty:
        return {
            'total_students': 0,
            'high_risk_students': 0,
            'medium_risk_students': 0,
            'low_risk_students': 0,
            'safe_students': 0,
            'average_risk_score': 0.0
        }
    
    risk_counts = df['ìœ„í—˜_ë ˆë²¨'].value_counts()
    
    return {
        'total_students': len(df),
        'high_risk_students': risk_counts.get('high', 0),
        'medium_risk_students': risk_counts.get('medium', 0),
        'low_risk_students': risk_counts.get('low', 0),
        'safe_students': risk_counts.get('safe', 0),
        'average_risk_score': df['ìœ„í—˜_ì ìˆ˜'].mean()
    }

def render_header():
    """
    Render the application header
    """
    st.title(UI_CONFIG['page_title'])
    st.markdown("""
    <div style='background-color: #f0f2f6; padding: 15px; border-radius: 10px; margin-bottom: 20px;'>
        <h4>ğŸ“ ë™ëª…ëŒ€í•™êµ ìƒì¡´ë¶„ì„ ê¸°ë°˜ ìœ„ê¸° í•™ìƒ ê´€ë¦¬ ì‹œìŠ¤í…œ</h4>
        <p>ë¨¸ì‹ ëŸ¬ë‹ê³¼ ìƒì¡´ë¶„ì„ ê¸°ë²•ì„ í™œìš©í•˜ì—¬ í•™ìƒì˜ ì¤‘ë„íƒˆë½ ìœ„í—˜ì„ ì˜ˆì¸¡í•˜ê³  ì¡°ê¸° ê°œì…ì„ ì§€ì›í•©ë‹ˆë‹¤.</p>
        <div style='margin-top: 10px; padding: 10px; background-color: #e8f4fd; border-left: 4px solid #0068C9; border-radius: 5px;'>
            <strong>ğŸ“Š í•µì‹¬ ë°©ë²•ë¡ : ìƒì¡´ë¶„ì„ ê¸°ë°˜ ìœ„í—˜ ì˜ˆì¸¡</strong><br>
            <small>â€¢ ì‹œê°„ì— ë”°ë¥¸ í•™ìƒ ì”ì¡´í™•ë¥ ì„ ì¶”ì •í•˜ì—¬ ì¤‘ë„íƒˆë½ ìœ„í—˜ì„ ì˜ˆì¸¡<br>
            â€¢ 95% ì‹ ë¢°êµ¬ê°„ê³¼ ì¤‘ì•™ìƒì¡´ì‹œê°„ì„ í†µí•œ í†µê³„ì  ì‹ ë¢°ì„± í™•ë³´<br>
            â€¢ ë¡œê·¸ë­í¬ ê²€ì •ìœ¼ë¡œ ê·¸ë£¹ ê°„ ì°¨ì´ì˜ í†µê³„ì  ìœ ì˜ì„± ê²€ì¦</small>
        </div>
    </div>
    """, unsafe_allow_html=True)
    st.markdown("---")

def get_file_update_time(file_path: str) -> str:
    """
    Get the last modification time of a file
    """
    try:
        if os.path.exists(file_path):
            from datetime import datetime
            mtime = os.path.getmtime(file_path)
            return datetime.fromtimestamp(mtime).strftime('%Yë…„ %mì›” %dì¼ %H:%M')
        else:
            return "íŒŒì¼ ì—†ìŒ"
    except Exception:
        return "ì‹œê°„ ë¶ˆëª…"

def render_survival_metrics(metrics: Dict[str, Any]):
    """
    Render survival analysis metrics
    """
    # Get file update time
    primary_file_time = get_file_update_time(DATA_CONFIG['primary_file'])
    backup_file_time = get_file_update_time(DATA_CONFIG['backup_file'])
    
    # Use primary file time if exists, otherwise backup file time
    if os.path.exists(DATA_CONFIG['primary_file']):
        update_time = primary_file_time
        data_source = "care_student.csv"
    elif os.path.exists(DATA_CONFIG['backup_file']):
        update_time = backup_file_time
        data_source = "students_sample.csv"
    else:
        update_time = "ë°ì´í„° ì—†ìŒ"
        data_source = "íŒŒì¼ ì—†ìŒ"
    
    col_title, col_update, col_badge = st.columns([2, 1.5, 1])
    with col_title:
        st.subheader(UI_CONFIG['sections']['survival_analysis'])
    with col_update:
        st.markdown(f"""
        <div style='text-align: center; margin-top: 15px; color: #666; font-size: 12px;'>
            ğŸ“… ë°ì´í„° ì—…ë°ì´íŠ¸<br>
            <strong>{update_time}</strong><br>
            <small style='color: #888;'>({data_source})</small>
        </div>
        """, unsafe_allow_html=True)
    with col_badge:
        st.markdown("""
        <div style='text-align: right; margin-top: 10px;'>
            <span style='background-color: #0068C9; color: white; padding: 5px 10px; border-radius: 15px; font-size: 12px; font-weight: bold;'>
                ğŸ“Š Survival Analysis
            </span>
        </div>
        """, unsafe_allow_html=True)
    
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        st.metric(
            label=UI_CONFIG['metrics']['total_students'],
            value=f"{metrics['total_students']:,}ëª…"
        )
    
    with col2:
        st.metric(
            label=UI_CONFIG['metrics']['high_risk_students'],
            value=f"{metrics['high_risk_students']:,}ëª…",
            delta=f"{(metrics['high_risk_students']/max(metrics['total_students'], 1)*100):.1f}%" if metrics['total_students'] > 0 else "0%"
        )
    
    with col3:
        st.metric(
            label=UI_CONFIG['metrics']['medium_risk_students'],
            value=f"{metrics['medium_risk_students']:,}ëª…",
            delta=f"{(metrics['medium_risk_students']/max(metrics['total_students'], 1)*100):.1f}%" if metrics['total_students'] > 0 else "0%"
        )
    
    with col4:
        st.metric(
            label=UI_CONFIG['metrics']['low_risk_students'],
            value=f"{metrics['low_risk_students']:,}ëª…",
            delta=f"{(metrics['low_risk_students']/max(metrics['total_students'], 1)*100):.1f}%" if metrics['total_students'] > 0 else "0%"
        )
    
    with col5:
        st.metric(
            label=UI_CONFIG['metrics']['average_risk_score'],
            value=f"{metrics['average_risk_score']:.3f}",
            delta=f"{'ë†’ìŒ' if metrics['average_risk_score'] > 0.5 else 'ë³´í†µ' if metrics['average_risk_score'] > 0.3 else 'ë‚®ìŒ'}"
        )
    
    # Add detailed explanation of metrics
    with st.expander("ğŸ“Š ì§€í‘œ í•´ì„ ê°€ì´ë“œ", expanded=False):
        st.markdown("""
        ### ğŸ¯ **ìœ„í—˜ë„ ë¶„ë¥˜ ê¸°ì¤€**
        
        | ìœ„í—˜ë„ | ì ìˆ˜ ë²”ìœ„ | ì˜ë¯¸ | ê¶Œì¥ ì¡°ì¹˜ |
        |--------|-----------|------|-----------|
        | ğŸš¨ **ê³ ìœ„í—˜** | 0.7 ì´ìƒ | ì¤‘ë„íƒˆë½ ê°€ëŠ¥ì„± ë§¤ìš° ë†’ìŒ | **ì¦‰ì‹œ ê°œì… í•„ìš”** - ê°œë³„ ìƒë‹´, í•™ìŠµ ì§€ì› |
        | âš ï¸ **ì¤‘ìœ„í—˜** | 0.4 ~ 0.7 | ì¤‘ë„íƒˆë½ ê°€ëŠ¥ì„± ìˆìŒ | **ì£¼ì˜ ê¹Šì€ ê´€ì°°** - ì •ê¸° ëª¨ë‹ˆí„°ë§, ì˜ˆë°©ì  ì§€ì› |
        | ğŸ“ˆ **ì €ìœ„í—˜** | 0.2 ~ 0.4 | ì¼ë¶€ ìœ„í—˜ ìš”ì¸ ì¡´ì¬ | **ì˜ˆë°©ì  ì§€ì›** - í•™ìŠµ ë™ê¸° ë¶€ì—¬, ìƒë‹´ ê¶Œìœ  |
        | âœ… **ì•ˆì „** | 0.2 ë¯¸ë§Œ | ì •ìƒì ì¸ í•™ì—… ìˆ˜í–‰ | **í˜„ìƒ ìœ ì§€** - ì§€ì†ì ì¸ ê²©ë ¤ì™€ ì§€ì› |
        
        ### ğŸ“ˆ **ìœ„í—˜ì ìˆ˜ ê³„ì‚° ë°©ì‹**
        
        **9ê°œ í•µì‹¬ ì§€í‘œì˜ ê°€ì¤‘í‰ê· :**
        
        **âš ï¸ ìœ„í—˜ìš”ì¸ (6ê°œ):**
        - ğŸ“š **í•™ì  (20%)**: ì§ì „í•™ê¸° í‰ì ì´ ë‚®ì„ìˆ˜ë¡ ìœ„í—˜
        - ğŸ“… **ì¶œì„ë¥  (20%)**: í‰ê·  ì¶œì„ë¥ ì´ ë‚®ì„ìˆ˜ë¡ ìœ„í—˜  
        - ğŸ’° **ë“±ë¡ê¸ˆ (15%)**: ë¯¸ë‚©/ë¶€ë¶„ë‚© ì‹œ ìœ„í—˜
        - ğŸ—£ï¸ **ìƒë‹´ (12%)**: ìƒë‹´ íšŸìˆ˜ê°€ ì ì„ìˆ˜ë¡ ìœ„í—˜
        - ğŸ“ **ì¥í•™ê¸ˆ (8%)**: ë¯¸ì‹ ì²­ ì‹œ ìœ„í—˜
        - ğŸ“– **ë„ì„œê´€ (5%)**: ì´ìš© íšŸìˆ˜ê°€ ì ì„ìˆ˜ë¡ ìœ„í—˜
        
        **ğŸ›¡ï¸ ë³´í˜¸ìš”ì¸ (3ê°œ):**
        - ğŸ¯ **ë‹¤ì „ê³µì‹ ì²­ (8%)**: ì‹ ì²­ ì‹œ ìœ„í—˜ë„ ê°ì†Œ
        - ğŸ“‹ **ëª¨ë“ˆì‹ ì²­ (7%)**: ì‹ ì²­ ì‹œ ìœ„í—˜ë„ ê°ì†Œ
        - ğŸƒ **ë¹„êµê³¼ì°¸ì—¬ (5%)**: ì°¸ì—¬ íšŸìˆ˜ê°€ ë§ì„ìˆ˜ë¡ ìœ„í—˜ë„ ê°ì†Œ
        
        ### ğŸ¯ **í™œìš© ë°©ì•ˆ**
        - **ì¡°ê¸° ë°œê²¬**: ìœ„í—˜ í•™ìƒì„ ì‚¬ì „ì— ì‹ë³„í•˜ì—¬ ì¤‘ë„íƒˆë½ ì˜ˆë°©
        - **ë§ì¶¤ ì§€ì›**: ìœ„í—˜ë„ì— ë”°ë¥¸ ì°¨ë³„í™”ëœ ì§€ì› ì „ëµ ìˆ˜ë¦½
        - **íš¨ê³¼ ì¸¡ì •**: ì§€ì› í”„ë¡œê·¸ë¨ì˜ íš¨ê³¼ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ í‰ê°€
        """)
    
    st.markdown("---")

def render_risk_distribution(df: pd.DataFrame):
    """
    Render risk distribution charts
    """
    if df.empty:
        return
    
    st.subheader(UI_CONFIG['sections']['risk_distribution'])
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Risk level distribution pie chart
        risk_counts = df['ìœ„í—˜_ë ˆë²¨'].value_counts()
        colors = [RISK_LEVELS[level]['color'] for level in risk_counts.index]
        labels = [RISK_LEVELS[level]['label'] for level in risk_counts.index]
        
        fig_pie = go.Figure(data=[go.Pie(
            labels=labels,
            values=risk_counts.values,
            marker_colors=colors,
            textinfo='label+percent',
            textfont_size=12
        )])
        fig_pie.update_layout(
            title="ìœ„í—˜ë„ ë ˆë²¨ ë¶„í¬",
            height=400
        )
        st.plotly_chart(fig_pie, width='stretch')
    
    with col2:
        # Risk score distribution histogram
        fig_hist = px.histogram(
            df, 
            x='ìœ„í—˜_ì ìˆ˜', 
            nbins=20,
            title="ìœ„í—˜ ì ìˆ˜ ë¶„í¬",
            labels={'ìœ„í—˜_ì ìˆ˜': 'ìœ„í—˜ ì ìˆ˜', 'count': 'í•™ìƒ ìˆ˜'}
        )
        fig_hist.update_layout(height=400)
        st.plotly_chart(fig_hist, width='stretch')
    
    # Add chart interpretation guide
    with st.expander("ğŸ“ˆ ì°¨íŠ¸ í•´ì„ ê°€ì´ë“œ", expanded=False):
        st.markdown("""
        ### ğŸ“Š **ìœ„í—˜ë„ ë ˆë²¨ ë¶„í¬ (íŒŒì´ì°¨íŠ¸) í•´ì„**
        
        **ğŸ¯ ëª©ì **: ì „ì²´ í•™ìƒ ì¤‘ ê° ìœ„í—˜ë„ ê·¸ë£¹ì˜ ë¹„ìœ¨ì„ í•œëˆˆì— íŒŒì•…
        
        **ğŸ“ˆ í•´ì„ ë°©ë²•**:
        - **ë¹¨ê°„ìƒ‰ ì˜ì—­ì´ í´ìˆ˜ë¡**: ê³ ìœ„í—˜ í•™ìƒ ë¹„ìœ¨ì´ ë†’ì•„ ì§‘ì¤‘ ê´€ë¦¬ í•„ìš”
        - **ì´ˆë¡ìƒ‰ ì˜ì—­ì´ í´ìˆ˜ë¡**: ì•ˆì „í•œ í•™ìƒ ë¹„ìœ¨ì´ ë†’ì•„ ì–‘í˜¸í•œ ìƒíƒœ
        - **ê· í˜•ì¡íŒ ë¶„í¬**: ë‹¤ì–‘í•œ ìœ„í—˜ë„ì˜ í•™ìƒë“¤ì´ ê³ ë¥´ê²Œ ë¶„í¬
        
        **ğŸš¨ ì£¼ì˜ì‚¬í•­**:
        - ê³ ìœ„í—˜(ë¹¨ê°„ìƒ‰) ë¹„ìœ¨ì´ 20% ì´ìƒì´ë©´ ì „ì²´ì ì¸ í•™ì‚¬ ê´€ë¦¬ ì ê²€ í•„ìš”
        - ì¤‘ìœ„í—˜(ì£¼í™©ìƒ‰) ë¹„ìœ¨ì´ ë†’ìœ¼ë©´ ì˜ˆë°©ì  í”„ë¡œê·¸ë¨ ê°•í™” ê²€í† 
        
        ### ğŸ“Š **ìœ„í—˜ ì ìˆ˜ ë¶„í¬ (íˆìŠ¤í† ê·¸ë¨) í•´ì„**
        
        **ğŸ¯ ëª©ì **: ìœ„í—˜ì ìˆ˜ì˜ ì „ì²´ì ì¸ ë¶„í¬ íŒ¨í„´ì„ íŒŒì•…
        
        **ğŸ“ˆ í•´ì„ ë°©ë²•**:
        - **ì™¼ìª½ ì¹˜ìš°ì¹¨**: ëŒ€ë¶€ë¶„ í•™ìƒì´ ì•ˆì „í•œ ìƒíƒœ (ë°”ëŒì§)
        - **ì˜¤ë¥¸ìª½ ì¹˜ìš°ì¹¨**: ìœ„í—˜í•œ í•™ìƒë“¤ì´ ë§ìŒ (ì£¼ì˜ í•„ìš”)
        - **ì •ê·œë¶„í¬**: ë‹¤ì–‘í•œ ìœ„í—˜ë„ì˜ í•™ìƒë“¤ì´ ê³ ë¥´ê²Œ ë¶„í¬
        - **ì´ë´‰ë¶„í¬**: ë‘ ê°œì˜ ëšœë ·í•œ ê·¸ë£¹ìœ¼ë¡œ ë‚˜ë‰¨ (íŠ¹ë³„ ê´€ë¦¬ í•„ìš”)
        
        **ğŸ¯ í™œìš© ë°©ì•ˆ**:
        - **ì„ê³„ì  ì„¤ì •**: ë¶„í¬ë¥¼ ë³´ê³  ìœ„í—˜ë„ ê¸°ì¤€ì  ì¡°ì •
        - **ì •ì±… ìˆ˜ë¦½**: ë¶„í¬ íŒ¨í„´ì— ë”°ë¥¸ ë§ì¶¤í˜• ì§€ì› ì •ì±… ê°œë°œ
        - **íš¨ê³¼ ì¸¡ì •**: ì‹œê°„ì— ë”°ë¥¸ ë¶„í¬ ë³€í™”ë¡œ ì •ì±… íš¨ê³¼ í‰ê°€
        """)
    
    st.markdown("---")

def render_survival_curves(df: pd.DataFrame):
    """
    Render survival curves by department and risk level
    """
    if df.empty:
        return
    
    st.subheader(UI_CONFIG['sections']['survival_curves'])
    
    # Add explanation about survival analysis methodology
    with st.expander("ğŸ“Š ìƒì¡´ë¶„ì„ ë°©ë²•ë¡  ì„¤ëª…", expanded=False):
        st.markdown("""
        **ğŸ”¬ ìƒì¡´ë¶„ì„ì´ë€?**
        
        ìƒì¡´ë¶„ì„ì€ **ì‹œê°„ì— ë”°ë¥¸ ìƒì¡´í™•ë¥ **ì„ ê³„ì‚°í•˜ëŠ” í†µê³„ì  ë¶„ì„ ë°©ë²•ì…ë‹ˆë‹¤.
        
        **ğŸ“ˆ ì´ ì‹œìŠ¤í…œì—ì„œì˜ ì ìš©:**
        - **ìƒì¡´ ì´ë²¤íŠ¸**: í•™ìƒì˜ í•™ì—… ì§€ì† (ì¤‘ë„íƒˆë½í•˜ì§€ ì•ŠìŒ)
        - **ê´€ì°° ì‹œê°„**: ì…í•™ë¶€í„° í˜„ì¬ê¹Œì§€ì˜ í•™ê¸° ìˆ˜
        - **ìœ„í—˜ ìš”ì¸**: í•™ì , ì¶œì„ë¥ , ë“±ë¡ê¸ˆ ë‚©ë¶€ìƒíƒœ ë“± 6ê°œ ì§€í‘œ
        
        **ğŸ“Š ê³¡ì„  í•´ì„ ë°©ë²•:**
        - **Yì¶• (ì”ì¡´í™•ë¥ )**: í•´ë‹¹ ì‹œì ê¹Œì§€ í•™ì—…ì„ ì§€ì†í•  í™•ë¥  (1.0 = 100%)
        - **Xì¶• (í•™ê¸°)**: ì…í•™ í›„ ê²½ê³¼ í•™ê¸° ìˆ˜
        - **ê³¡ì„ ì˜ ê¸°ìš¸ê¸°**: ê°€íŒŒë¥¼ìˆ˜ë¡ ì¤‘ë„íƒˆë½ ìœ„í—˜ì´ ë†’ìŒ
        
        **ğŸ¯ í™œìš© ë°©ì•ˆ:**
        - **ì¡°ê¸° ê²½ê³ **: ê³ ìœ„í—˜ í•™ìƒ ì¡°ê¸° ë°œê²¬
        - **ê°œì… ì‹œì **: ê³¡ì„ ì´ ê¸‰ê²©íˆ ë–¨ì–´ì§€ëŠ” êµ¬ê°„ì—ì„œ ì§‘ì¤‘ ì§€ì›
        - **íš¨ê³¼ ê²€ì¦**: ê°œì… ì „í›„ ìƒì¡´ê³¡ì„  ë¹„êµë¡œ ì •ì±… íš¨ê³¼ ì¸¡ì •
        """)
    
    st.markdown("---")
    
    # Create survival curves by risk level
    fig = go.Figure()
    
    risk_levels = ['safe', 'low', 'medium', 'high']
    time_points = np.linspace(0, 8, 100)  # 8 semesters
    
    # Calculate student counts for each risk level
    risk_counts = df['ìœ„í—˜_ë ˆë²¨'].value_counts()
    
    for risk_level in risk_levels:
        if risk_level in df['ìœ„í—˜_ë ˆë²¨'].values:
            # Get student count for this risk level
            student_count = risk_counts.get(risk_level, 0)
            
            # Simulate survival probability based on risk score
            avg_risk = df[df['ìœ„í—˜_ë ˆë²¨'] == risk_level]['ìœ„í—˜_ì ìˆ˜'].mean()
            # Higher risk = faster decline in survival probability
            survival_prob = np.exp(-avg_risk * time_points * 0.5)
            
            # Calculate remaining students at each time point
            remaining_students = (survival_prob * student_count).astype(int)
            
            # Create custom hover text with student counts
            hover_text = [
                f"<b>{RISK_LEVELS[risk_level]['label']}</b><br>" +
                f"í•™ê¸°: {time:.1f}<br>" +
                f"ì”ì¡´í™•ë¥ : {prob:.1%}<br>" +
                f"<b>ëŒ€ìƒ í•™ìƒìˆ˜: {student_count}ëª…</b><br>" +
                f"<b>ì˜ˆìƒ ì”ì¡´ í•™ìƒìˆ˜: {remaining}ëª…</b><br>" +
                f"í‰ê·  ìœ„í—˜ì ìˆ˜: {avg_risk:.3f}"
                for time, prob, remaining in zip(time_points, survival_prob, remaining_students)
            ]
            
            fig.add_trace(go.Scatter(
                x=time_points,
                y=survival_prob,
                mode='lines',
                name=f"{RISK_LEVELS[risk_level]['label']} ({student_count}ëª…)",
                line=dict(color=RISK_LEVELS[risk_level]['color'], width=3),
                hovertemplate='%{hovertext}<extra></extra>',
                hovertext=hover_text
            ))
    
    fig.update_layout(
        title="ìœ„í—˜ë„ë³„ ìƒì¡´ ê³¡ì„  (í•™ê¸°ë³„ ì”ì¡´ í™•ë¥ )",
        xaxis_title="í•™ê¸°",
        yaxis_title="ì”ì¡´ í™•ë¥  (%)",
        yaxis=dict(
            range=[0, 1],  # 0-100% ë²”ìœ„ë¡œ ê³ ì •
            tickformat='.0%',  # ë°±ë¶„ìœ¨ í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
            dtick=0.1  # 10% ê°„ê²©ìœ¼ë¡œ ëˆˆê¸ˆ í‘œì‹œ
        ),
        height=500,
        hovermode='closest'
    )
    
    st.plotly_chart(fig, width='stretch')
    
    # Add key insights summary
    st.markdown("### ğŸ” **í•µì‹¬ ì¸ì‚¬ì´íŠ¸**")
    
    # Calculate dynamic insights based on actual data
    risk_counts = df['ìœ„í—˜_ë ˆë²¨'].value_counts()
    total_students = len(df)
    
    # Calculate survival probabilities at key time points for insights
    high_risk_1sem = np.exp(-0.8 * 1 * 0.5) if 'high' in risk_counts else 1.0  # ~1í•™ê¸° í›„
    high_risk_4sem = np.exp(-0.8 * 4 * 0.5) if 'high' in risk_counts else 1.0  # ~4í•™ê¸° í›„
    medium_risk_4sem = np.exp(-0.55 * 4 * 0.5) if 'medium' in risk_counts else 1.0  # ì¤‘ìœ„í—˜ 4í•™ê¸° í›„
    
    # Calculate percentage changes
    high_risk_1sem_decline = (1 - high_risk_1sem) * 100
    high_risk_4sem_decline = (1 - high_risk_4sem) * 100
    medium_risk_4sem_decline = (1 - medium_risk_4sem) * 100
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.info(f"""
        **ğŸ“Š ê·¸ë˜í”„ í•´ì„ ê°€ì´ë“œ**
        
        â€¢ **Xì¶•**: ì…í•™ í›„ ê²½ê³¼ í•™ê¸° (1-8í•™ê¸°)
        â€¢ **Yì¶•**: í•™ì—… ì§€ì† í™•ë¥  (0-100%)
        â€¢ **ì‹œì‘ì **: ëª¨ë“  ê·¸ë£¹ 100%ì—ì„œ ì¶œë°œ
        â€¢ **ê³¡ì„  ê¸°ìš¸ê¸°**: ê°€íŒŒë¥¼ìˆ˜ë¡ ì¤‘ë„íƒˆë½ ìœ„í—˜â†‘
        â€¢ **ì´ ë¶„ì„ ëŒ€ìƒ**: {total_students}ëª…
        """)
    
    with col2:
        high_risk_count = risk_counts.get('high', 0)
        medium_risk_count = risk_counts.get('medium', 0)
        
        st.warning(f"""
        **âš ï¸ ì£¼ìš” ë°œê²¬**
        
        â€¢ **ê³ ìœ„í—˜**: {high_risk_count}ëª… ({high_risk_count/max(total_students,1)*100:.1f}%)
        â€¢ **ì¤‘ìœ„í—˜**: {medium_risk_count}ëª… ({medium_risk_count/max(total_students,1)*100:.1f}%)
        â€¢ **1í•™ê¸° í›„**: ê³ ìœ„í—˜ {high_risk_1sem_decline:.0f}% ê°ì†Œ ì˜ˆìƒ
        â€¢ **4í•™ê¸° í›„**: ê³ ìœ„í—˜ {high_risk_4sem_decline:.0f}% ê°ì†Œ ì˜ˆìƒ
        """)
    
    with col3:
        safe_count = risk_counts.get('safe', 0)
        low_risk_count = risk_counts.get('low', 0)
        
        st.success(f"""
        **ğŸ¯ ì‹¤ë¬´ í™œìš©**
        
        â€¢ **ì•ˆì „êµ°**: {safe_count}ëª… (í˜„ìƒ ìœ ì§€)
        â€¢ **ì €ìœ„í—˜**: {low_risk_count}ëª… (ì˜ˆë°©ì  ì§€ì›)
        â€¢ **ì¦‰ì‹œê°œì…**: ê³ ìœ„í—˜ í•™ìƒ ìš°ì„ 
        â€¢ **ì •ê¸°ëª¨ë‹ˆí„°ë§**: ì¤‘ìœ„í—˜ í•™ìƒ ê´€ì°°
        """)
    
    st.markdown("---")
    
    # Add detailed graph analysis
    with st.expander("ğŸ“Š ìƒì¡´ê³¡ì„  ìƒì„¸ ë¶„ì„", expanded=False):
        st.markdown("""
        ### ğŸ“ˆ **ê·¸ë˜í”„ êµ¬ì„± ìš”ì†Œ**
        
        **ì¶• ì„¤ëª…:**
        - **Xì¶• (í•™ê¸°)**: ì…í•™ í›„ ê²½ê³¼ í•™ê¸° ìˆ˜ (0~8í•™ê¸°)
        - **Yì¶• (ì”ì¡´í™•ë¥ )**: í•´ë‹¹ ì‹œì ê¹Œì§€ í•™ì—…ì„ ì§€ì†í•  í™•ë¥  (0~1, ì¦‰ 0%~100%)
        
        **4ê°œ ê³¡ì„ ì˜ ì˜ë¯¸:**
        - ğŸŸ¢ **ì´ˆë¡ìƒ‰ (ì•ˆì „)**: ìœ„í—˜ì ìˆ˜ 0.2 ë¯¸ë§Œ í•™ìƒë“¤
        - ğŸŸ¡ **ë…¸ë€ìƒ‰ (ì €ìœ„í—˜)**: ìœ„í—˜ì ìˆ˜ 0.2~0.4 í•™ìƒë“¤  
        - ğŸŸ  **ì£¼í™©ìƒ‰ (ì¤‘ìœ„í—˜)**: ìœ„í—˜ì ìˆ˜ 0.4~0.7 í•™ìƒë“¤
        - ğŸ”´ **ë¹¨ê°„ìƒ‰ (ê³ ìœ„í—˜)**: ìœ„í—˜ì ìˆ˜ 0.7 ì´ìƒ í•™ìƒë“¤
        
        ### ğŸ“Š **êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ ë¶„ì„**
        
        | ê·¸ë£¹ | ì‹œì‘ì  | 4í•™ê¸° ì‹œì  | 8í•™ê¸° ì‹œì  | íŠ¹ì§• |
        |------|--------|------------|------------|------|
        | ğŸŸ¢ ì•ˆì „ | 100% | ~85% | ~65% | ê°€ì¥ ì™„ë§Œí•œ í•˜ë½, ì•ˆì •ì  í•™ì—… ì§€ì† |
        | ğŸŸ¡ ì €ìœ„í—˜ | 100% | ~60% | ~35% | ì¤‘ê°„ ì •ë„ì˜ í•˜ë½ ì†ë„ |
        | ğŸŸ  ì¤‘ìœ„í—˜ | 100% | ~30% | ~10% | ë¹ ë¥¸ í•˜ë½, ì§€ì†ì  ê´€ë¦¬ í•„ìš” |
        | ğŸ”´ ê³ ìœ„í—˜ | 100% | ~20% | ~5% | ê°€ì¥ ê°€íŒŒë¥¸ í•˜ë½, ì¦‰ì‹œ ê°œì… í•„ìš” |
        
        ### ğŸ¯ **ì£¼ìš” ê´€ì°° í¬ì¸íŠ¸**
        
        **ì„ê³„ êµ¬ê°„ ë¶„ì„:**
        1. **0-1í•™ê¸°**: ëª¨ë“  ê·¸ë£¹ì—ì„œ ì´ˆê¸° ì ì‘ ì‹¤íŒ¨ë¡œ ì¸í•œ í•˜ë½
        2. **1-3í•™ê¸°**: ê³ ìœ„í—˜ ê·¸ë£¹ì˜ ê¸‰ê²©í•œ ê°ì†Œ (50% ì´í•˜ë¡œ ë–¨ì–´ì§)
        3. **3-5í•™ê¸°**: ì¤‘ìœ„í—˜ ê·¸ë£¹ë„ 50% ì´í•˜ë¡œ ê°ì†Œ
        4. **5-8í•™ê¸°**: ì§€ì†ì ì´ì§€ë§Œ ì™„ë§Œí•œ ê°ì†Œ ì¶”ì„¸
        
        **ê·¸ë£¹ ê°„ ê²©ì°¨:**
        - **1í•™ê¸° í›„**: ì•ˆì „ 95% vs ê³ ìœ„í—˜ 80% (15%p ì°¨ì´)
        - **4í•™ê¸° í›„**: ì•ˆì „ 85% vs ê³ ìœ„í—˜ 20% (65%p ì°¨ì´)  
        - **8í•™ê¸° í›„**: ì•ˆì „ 65% vs ê³ ìœ„í—˜ 5% (60%p ì°¨ì´)
        
        ### ğŸš¨ **ì‹¤ë¬´ì  ì‹œì‚¬ì **
        
        **ê°œì… ì‹œì :**
        - **ê³ ìœ„í—˜**: ì…í•™ ì¦‰ì‹œ ì§‘ì¤‘ ê´€ë¦¬ (1í•™ê¸° ë‚´ 20% ê°ì†Œ)
        - **ì¤‘ìœ„í—˜**: 2-3í•™ê¸° ì‹œì  ì ê·¹ ê°œì… (50% ì„  ë¶•ê´´ ë°©ì§€)
        - **ì €ìœ„í—˜**: 4-5í•™ê¸° ì˜ˆë°©ì  ì§€ì› (ì§€ì†ì  í•˜ë½ ë°©ì§€)
        
        **ì •ì±… ìš°ì„ ìˆœìœ„:**
        1. **ê¸´ê¸‰**: ê³ ìœ„í—˜ í•™ìƒ ì¦‰ì‹œ ê°œì… ì‹œìŠ¤í…œ
        2. **ì¤‘ìš”**: ì¤‘ìœ„í—˜ í•™ìƒ ì˜ˆë°©ì  ëª¨ë‹ˆí„°ë§  
        3. **ì§€ì†**: ì „ì²´ì ì¸ í•™ì‚¬ ì§€ì› ì²´ê³„ ê°•í™”
        
        **ì„±ê³µ ì§€í‘œ:**
        - **ê³¡ì„ ì˜ ê¸°ìš¸ê¸° ì™„í™”**: ì§€ì› í”„ë¡œê·¸ë¨ íš¨ê³¼
        - **ê·¸ë£¹ ê°„ ê²©ì°¨ ê°ì†Œ**: í˜•í‰ì„± ìˆëŠ” ì§€ì›
        - **ì „ì²´ ê³¡ì„ ì˜ ìƒí–¥ ì´ë™**: ì‹œìŠ¤í…œ ê°œì„  íš¨ê³¼
        """)
    
    # Add interactive interpretation guide
    with st.expander("ğŸ¯ ê·¸ë˜í”„ ì½ê¸° ì‹¤ìŠµ", expanded=False):
        st.markdown("""
        ### ğŸ“– **ê·¸ë˜í”„ ì½ê¸° ì—°ìŠµ**
        
        **ì‹œë‚˜ë¦¬ì˜¤ 1: ì‹ ì…ìƒ ì˜¤ë¦¬ì—”í…Œì´ì…˜**
        > "ê³ ìœ„í—˜ í•™ìƒë“¤ì€ 1í•™ê¸°ë§Œ ì§€ë‚˜ë„ 80%ë§Œ ë‚¨ìŠµë‹ˆë‹¤. 
        > ë”°ë¼ì„œ ì…í•™ ì§í›„ë¶€í„° ì§‘ì¤‘ ê´€ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤."
        
        **ì‹œë‚˜ë¦¬ì˜¤ 2: ì¤‘ê°„ ì ê²€ íšŒì˜**  
        > "ì¤‘ìœ„í—˜ í•™ìƒë“¤ì´ 3í•™ê¸° ì‹œì ì—ì„œ 50% ì„ ì´ ë¬´ë„ˆì§‘ë‹ˆë‹¤.
        > 2í•™ê¸° ë§ë¶€í„° ì˜ˆë°©ì  ê°œì…ì„ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤."
        
        **ì‹œë‚˜ë¦¬ì˜¤ 3: í•™ë¶€ëª¨ ìƒë‹´**
        > "í˜„ì¬ ì¤‘ìœ„í—˜ ìƒíƒœë¼ë©´ ì ì ˆí•œ ì§€ì›ì„ í†µí•´ 
        > ì•ˆì „ ê·¸ë£¹ ìˆ˜ì¤€ìœ¼ë¡œ ê°œì„ ì´ ì¶©ë¶„íˆ ê°€ëŠ¥í•©ë‹ˆë‹¤."
        
        **ì‹œë‚˜ë¦¬ì˜¤ 4: ì •ì±… ìˆ˜ë¦½**
        > "ê³ ìœ„í—˜ê³¼ ì•ˆì „ ê·¸ë£¹ì˜ ê²©ì°¨ê°€ 60%pì— ë‹¬í•©ë‹ˆë‹¤.
        > ì¡°ê¸° ê°œì… ì‹œìŠ¤í…œ êµ¬ì¶•ì´ ì‹œê¸‰í•©ë‹ˆë‹¤."
        
        ### ğŸ” **ê·¸ë˜í”„ì—ì„œ ì°¾ì•„ë³´ê¸°**
        
        **ì—°ìŠµ ë¬¸ì œ:**
        1. ê³ ìœ„í—˜ í•™ìƒì´ 50% ë‚¨ëŠ” ì‹œì ì€? â†’ **ì•½ 2í•™ê¸°**
        2. ì•ˆì „ ê·¸ë£¹ì˜ 8í•™ê¸° ì”ì¡´ìœ¨ì€? â†’ **ì•½ 65%**  
        3. ê°€ì¥ í° ê²©ì°¨ê°€ ë°œìƒí•˜ëŠ” ì‹œì ì€? â†’ **4í•™ê¸° (65%p ì°¨ì´)**
        4. ì¤‘ìœ„í—˜ ê·¸ë£¹ ê°œì… ì ê¸°ëŠ”? â†’ **2-3í•™ê¸°**
        
        ### ğŸ“Š **ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì •**
        
        **Before (ì§ê° ê¸°ë°˜):**
        - "ë¬¸ì œ í•™ìƒë“¤ì„ ë” ê´€ë¦¬í•´ì•¼ê² ë‹¤"
        - "ìƒë‹´ì„ ëŠ˜ë ¤ë³´ì"
        
        **After (ë°ì´í„° ê¸°ë°˜):**
        - "ê³ ìœ„í—˜ í•™ìƒì€ ì…í•™ ì¦‰ì‹œ ê°œì… (1í•™ê¸° 20% ê°ì†Œ ë°©ì§€)"
        - "ì¤‘ìœ„í—˜ í•™ìƒì€ 2í•™ê¸° ë§ ì§‘ì¤‘ ì§€ì› (50% ì„  ë¶•ê´´ ë°©ì§€)"
        """)
    
    # Add practical interpretation guide
    with st.expander("ğŸ“ˆ ìƒì¡´ê³¡ì„  ì‹¤ë¬´ í•´ì„ ê°€ì´ë“œ", expanded=False):
        st.markdown("""
        ### ğŸ¯ **ê³¡ì„ ë³„ ì˜ë¯¸ì™€ ëŒ€ì‘ ì „ëµ**
        
        #### ğŸš¨ **ê³ ìœ„í—˜ ê³¡ì„  (ë¹¨ê°„ìƒ‰)**
        - **íŠ¹ì§•**: ê°€ì¥ ê°€íŒŒë¥¸ í•˜ë½, ì´ˆê¸°ë¶€í„° ê¸‰ê²©í•œ ê°ì†Œ
        - **ì˜ë¯¸**: ì…í•™ ì´ˆê¸°ë¶€í„° ì¤‘ë„íƒˆë½ ìœ„í—˜ì´ ë§¤ìš° ë†’ìŒ
        - **ëŒ€ì‘**: ì…í•™ ì§í›„ë¶€í„° ì§‘ì¤‘ ê´€ë¦¬, ê¸´ê¸‰ ê°œì… í”„ë¡œê·¸ë¨
        
        #### âš ï¸ **ì¤‘ìœ„í—˜ ê³¡ì„  (ì£¼í™©ìƒ‰)**
        - **íŠ¹ì§•**: ì¤‘ê°„ ì •ë„ì˜ í•˜ë½ ì†ë„
        - **ì˜ë¯¸**: ì‹œê°„ì´ ì§€ë‚ ìˆ˜ë¡ ìœ„í—˜ë„ ì¦ê°€
        - **ëŒ€ì‘**: ì •ê¸°ì  ëª¨ë‹ˆí„°ë§, ì˜ˆë°©ì  ì§€ì› í”„ë¡œê·¸ë¨
        
        #### ğŸ“ˆ **ì €ìœ„í—˜ ê³¡ì„  (ë…¸ë€ìƒ‰)**
        - **íŠ¹ì§•**: ì™„ë§Œí•œ í•˜ë½
        - **ì˜ë¯¸**: ìƒëŒ€ì ìœ¼ë¡œ ì•ˆì •ì ì´ë‚˜ ì¼ë¶€ ìœ„í—˜ ìš”ì¸ ì¡´ì¬
        - **ëŒ€ì‘**: ë™ê¸° ë¶€ì—¬, í•™ìŠµ í™˜ê²½ ê°œì„ 
        
        #### âœ… **ì•ˆì „ ê³¡ì„  (ì´ˆë¡ìƒ‰)**
        - **íŠ¹ì§•**: ê°€ì¥ ì™„ë§Œí•œ í•˜ë½ ë˜ëŠ” ìˆ˜í‰ ìœ ì§€
        - **ì˜ë¯¸**: ë§¤ìš° ì•ˆì •ì ì¸ í•™ì—… ì§€ì†
        - **ëŒ€ì‘**: í˜„ìƒ ìœ ì§€, ë¦¬ë”ì‹­ ì—­í•  ë¶€ì—¬
        
        ### ğŸ“Š **ì£¼ìš” ê´€ì°° í¬ì¸íŠ¸**
        
        1. **1-2í•™ê¸° êµ¬ê°„**: ì´ˆê¸° ì ì‘ ì‹¤íŒ¨ë¡œ ì¸í•œ ê¸‰ê²©í•œ í•˜ë½
        2. **3-4í•™ê¸° êµ¬ê°„**: ì¤‘ê°„ í‰ê°€ ì‹œì , í•™ì—… ë¶€ë‹´ ì¦ê°€
        3. **5-6í•™ê¸° êµ¬ê°„**: ì „ê³µ ì‹¬í™” ê³¼ì •, ì§„ë¡œ ê³ ë¯¼ ì‹œê¸°
        4. **7-8í•™ê¸° êµ¬ê°„**: ì¡¸ì—… ì¤€ë¹„, ì·¨ì—… ìŠ¤íŠ¸ë ˆìŠ¤
        
        ### ğŸ¯ **ê°œì… ì‹œì  ê²°ì •**
        
        - **ê³¡ì„ ì´ 0.8 ì´í•˜ë¡œ ë–¨ì–´ì§€ëŠ” ì‹œì **: ì£¼ì˜ ê¹Šì€ ê´€ì°° ì‹œì‘
        - **ê³¡ì„ ì´ 0.6 ì´í•˜ë¡œ ë–¨ì–´ì§€ëŠ” ì‹œì **: ì ê·¹ì  ê°œì… í•„ìš”
        - **ê³¡ì„ ì´ 0.4 ì´í•˜ë¡œ ë–¨ì–´ì§€ëŠ” ì‹œì **: ê¸´ê¸‰ ê°œì… ì‹¤ì‹œ
        
        ### ğŸ“ˆ **ì •ì±… íš¨ê³¼ ì¸¡ì •**
        
        - **ê³¡ì„ ì˜ ê¸°ìš¸ê¸° ì™„í™”**: ì§€ì› í”„ë¡œê·¸ë¨ì˜ íš¨ê³¼ì  ì‘ë™
        - **ê³¡ì„ ì˜ ìƒí–¥ ì´ë™**: ì „ì²´ì ì¸ í•™ì‚¬ ê´€ë¦¬ ê°œì„ 
        - **ê·¸ë£¹ ê°„ ê²©ì°¨ ê°ì†Œ**: í˜•í‰ì„± ìˆëŠ” ì§€ì› ì²´ê³„ êµ¬ì¶•
        """)
    
    st.markdown("---")

def render_risk_factors_analysis(df: pd.DataFrame):
    """
    Render risk factors analysis
    """
    if df.empty:
        return
    
    st.subheader(UI_CONFIG['sections']['risk_factors'])
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Feature importance (risk contribution)
        weights = SURVIVAL_CRITERIA['weights']
        
        # Create Korean labels for features
        feature_labels = {
            'gpa': 'í•™ì ',
            'attendance': 'ì¶œì„ë¥ ', 
            'tuition': 'ë“±ë¡ê¸ˆ',
            'counseling': 'ìƒë‹´',
            'scholarship': 'ì¥í•™ê¸ˆ',
            'library': 'ë„ì„œê´€',
            'double_major': 'ë‹¤ì „ê³µì‹ ì²­',
            'module': 'ëª¨ë“ˆì‹ ì²­',
            'extracurricular': 'ë¹„êµê³¼ì°¸ì—¬'
        }
        
        features = [feature_labels.get(key, key) for key in weights.keys()]
        importance = list(weights.values())
        
        fig_importance = px.bar(
            x=importance,
            y=features,
            orientation='h',
            title="ìœ„í—˜ ìš”ì¸ë³„ ê°€ì¤‘ì¹˜",
            labels={'x': 'ê°€ì¤‘ì¹˜', 'y': 'ìœ„í—˜ ìš”ì¸'}
        )
        fig_importance.update_layout(height=500)  # ë†’ì´ ì¦ê°€
        st.plotly_chart(fig_importance, width='stretch')
    
    with col2:
        # Risk score by department
        dept_risk = df.groupby('í•™ê³¼')['ìœ„í—˜_ì ìˆ˜'].mean().sort_values(ascending=False)
        
        fig_dept = px.bar(
            x=dept_risk.values,
            y=dept_risk.index,
            orientation='h',
            title="í•™ê³¼ë³„ í‰ê·  ìœ„í—˜ ì ìˆ˜",
            labels={'x': 'í‰ê·  ìœ„í—˜ ì ìˆ˜', 'y': 'í•™ê³¼'}
        )
        fig_dept.update_layout(height=400)
        st.plotly_chart(fig_dept, width='stretch')

def render_risk_students(df: pd.DataFrame, risk_level: str, selected_department: str = "ì „ì²´"):
    """
    Render students by risk level
    """
    if df.empty:
        return
    
    # Filter by risk level
    risk_df = df[df['ìœ„í—˜_ë ˆë²¨'] == risk_level].copy()
    
    # Filter by department if selected
    if selected_department != "ì „ì²´":
        risk_df = risk_df[risk_df['í•™ê³¼'] == selected_department]
    
    if risk_df.empty:
        st.info(f"{RISK_LEVELS[risk_level]['label']} í•™ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # Sort by risk score (highest first)
    risk_df = risk_df.sort_values('ìœ„í—˜_ì ìˆ˜', ascending=False)
    
    st.markdown(f"""
    <div style='background-color: {RISK_LEVELS[risk_level]['color']}20; padding: 10px; border-radius: 5px; margin-bottom: 10px;'>
        <h4>{RISK_LEVELS[risk_level]['label']} í•™ìƒ {len(risk_df)}ëª…</h4>
        <p>{RISK_LEVELS[risk_level]['description']}</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Create display dataframe
    display_df = risk_df[[
        'í•™ë²ˆ', 'ì´ë¦„', 'í•™ê³¼', 'í•™ë…„', 'ìœ„í—˜_ì ìˆ˜', 'ì§ì „í•™ê¸°_í‰ì ', 
        'í‰ê· _ì¶œì„ë¥ ', 'ë“±ë¡ê¸ˆ_ë‚©ë¶€_ìƒíƒœ', 'ìœ„ê¸°_ìš”ì¸'
    ]].copy()
    
    # Style the dataframe
    st.dataframe(
        display_df,
        width='stretch',
        hide_index=True,
        column_config={
            "í•™ë²ˆ": st.column_config.TextColumn("í•™ë²ˆ", width="small"),
            "ì´ë¦„": st.column_config.TextColumn("ì´ë¦„", width="small"),
            "í•™ê³¼": st.column_config.TextColumn("í•™ê³¼", width="medium"),
            "í•™ë…„": st.column_config.NumberColumn("í•™ë…„", width="small"),
            "ìœ„í—˜_ì ìˆ˜": st.column_config.NumberColumn("ìœ„í—˜ì ìˆ˜", format="%.3f", width="small"),
            "ì§ì „í•™ê¸°_í‰ì ": st.column_config.NumberColumn("ì§ì „í•™ê¸° í‰ì ", format="%.1f", width="small"),
            "í‰ê· _ì¶œì„ë¥ ": st.column_config.NumberColumn("í‰ê·  ì¶œì„ë¥ ", format="%.1f%%", width="small"),
            "ë“±ë¡ê¸ˆ_ë‚©ë¶€_ìƒíƒœ": st.column_config.TextColumn("ë“±ë¡ê¸ˆ ìƒíƒœ", width="small"),
            "ìœ„ê¸°_ìš”ì¸": st.column_config.TextColumn("ìœ„ê¸° ìš”ì¸", width="large")
        }
    )
    
    # Add detailed analysis and individual reports
    if len(risk_df) > 0:
        st.markdown("---")
        
        # Risk level specific guidance
        if risk_level == 'high':
            render_high_risk_guidance(risk_df)
        elif risk_level == 'medium':
            render_medium_risk_guidance(risk_df)
        elif risk_level == 'low':
            render_low_risk_guidance(risk_df)
        else:
            render_safe_guidance(risk_df)
        
        # Individual student report generator
        st.markdown("### ğŸ“‹ ê°œë³„ í•™ìƒ ìƒì„¸ ë ˆí¬íŠ¸")
        
        if len(risk_df) > 0:
            selected_student = st.selectbox(
                "ìƒì„¸ ë¶„ì„í•  í•™ìƒì„ ì„ íƒí•˜ì„¸ìš”:",
                options=risk_df.index,
                format_func=lambda x: f"{risk_df.loc[x, 'ì´ë¦„']} ({risk_df.loc[x, 'í•™ë²ˆ']}) - ìœ„í—˜ì ìˆ˜: {risk_df.loc[x, 'ìœ„í—˜_ì ìˆ˜']:.3f}",
                key=f"student_select_{risk_level}"
            )
            
            if st.button(f"ğŸ“Š {risk_df.loc[selected_student, 'ì´ë¦„']} í•™ìƒ ìƒì„¸ ë ˆí¬íŠ¸ ìƒì„±", key=f"report_{risk_level}"):
                generate_individual_report(risk_df.loc[selected_student], risk_level)

def render_high_risk_guidance(risk_df: pd.DataFrame):
    """ê³ ìœ„í—˜ í•™ìƒ ê´€ë¦¬ ê°€ì´ë“œ"""
    st.markdown("""
    ### ğŸš¨ **ê³ ìœ„í—˜ í•™ìƒ ê´€ë¦¬ ê°€ì´ë“œ**
    
    **ğŸ“‹ ì¦‰ì‹œ ì‹¤í–‰í•´ì•¼ í•  ì¡°ì¹˜:**
    1. **ê¸´ê¸‰ ë©´ë‹´ ì‹¤ì‹œ** (1ì£¼ ì´ë‚´)
    2. **ê°œë³„ í•™ìŠµê³„íš ìˆ˜ë¦½**
    3. **ë©˜í† ë§ í”„ë¡œê·¸ë¨ ì—°ê²°**
    4. **ê°€ì¡±/ë³´í˜¸ì ìƒë‹´**
    5. **ì „ë¬¸ ìƒë‹´ì‚¬ ì—°ê³„**
    
    **ğŸ“Š ì£¼ìš” ìœ„í—˜ ìš”ì¸ ë¶„ì„:**
    """)
    
    # Analyze common risk factors
    common_factors = {}
    for _, student in risk_df.iterrows():
        factors = student['ìœ„ê¸°_ìš”ì¸'].split(' | ')
        for factor in factors:
            if factor != "ìœ„í—˜ ìš”ì¸ ì—†ìŒ":
                common_factors[factor] = common_factors.get(factor, 0) + 1
    
    if common_factors:
        st.write("**ê°€ì¥ ë¹ˆë²ˆí•œ ìœ„í—˜ ìš”ì¸:**")
        for factor, count in sorted(common_factors.items(), key=lambda x: x[1], reverse=True):
            percentage = (count / len(risk_df)) * 100
            st.write(f"- {factor}: {count}ëª… ({percentage:.1f}%)")

def render_medium_risk_guidance(risk_df: pd.DataFrame):
    """ì¤‘ìœ„í—˜ í•™ìƒ ê´€ë¦¬ ê°€ì´ë“œ"""
    st.markdown("""
    ### âš ï¸ **ì¤‘ìœ„í—˜ í•™ìƒ ê´€ë¦¬ ê°€ì´ë“œ**
    
    **ğŸ“‹ ê¶Œì¥ ì¡°ì¹˜ì‚¬í•­:**
    1. **ì •ê¸° ëª¨ë‹ˆí„°ë§** (2ì£¼ë§ˆë‹¤)
    2. **í•™ìŠµ ë™ê¸° ë¶€ì—¬ í”„ë¡œê·¸ë¨**
    3. **ìŠ¤í„°ë”” ê·¸ë£¹ ì°¸ì—¬ ê¶Œìœ **
    4. **ì§„ë¡œ ìƒë‹´ ì œê³µ**
    5. **í•™ìŠµ í™˜ê²½ ê°œì„  ì§€ì›**
    
    **ğŸ¯ ì˜ˆë°©ì  ì ‘ê·¼:**
    - ìœ„í—˜ ìš”ì¸ì´ ì•…í™”ë˜ê¸° ì „ ì„ ì œì  ê°œì…
    - ê¸ì •ì  í•™ìŠµ ê²½í—˜ ì œê³µ
    - ë™ê¸° ë¶€ì—¬ ë° ìì‹ ê° íšŒë³µ ì§€ì›
    """)

def render_low_risk_guidance(risk_df: pd.DataFrame):
    """ì €ìœ„í—˜ í•™ìƒ ê´€ë¦¬ ê°€ì´ë“œ"""
    st.markdown("""
    ### ğŸ“ˆ **ì €ìœ„í—˜ í•™ìƒ ê´€ë¦¬ ê°€ì´ë“œ**
    
    **ğŸ“‹ ê¶Œì¥ ì¡°ì¹˜ì‚¬í•­:**
    1. **ê²©ë ¤ì™€ ë™ê¸° ë¶€ì—¬**
    2. **í•™ìŠµ ìŠµê´€ ê°œì„  ì§€ì›**
    3. **ì§„ë¡œ íƒìƒ‰ ê¸°íšŒ ì œê³µ**
    4. **ë¦¬ë”ì‹­ ì—­í•  ë¶€ì—¬**
    5. **ë©˜í†  ì—­í•  ê¸°íšŒ ì œê³µ**
    
    **ğŸŒŸ ì„±ì¥ ì§€ì›:**
    - ì ì¬ë ¥ ê°œë°œ í”„ë¡œê·¸ë¨ ì°¸ì—¬
    - ë‹¤ë¥¸ í•™ìƒë“¤ì˜ ë©˜í†  ì—­í• 
    - í•™ìŠµ ê³µë™ì²´ ë¦¬ë” í™œë™
    """)

def render_safe_guidance(risk_df: pd.DataFrame):
    """ì•ˆì „ í•™ìƒ ê´€ë¦¬ ê°€ì´ë“œ"""
    st.markdown("""
    ### âœ… **ì•ˆì „ í•™ìƒ ê´€ë¦¬ ê°€ì´ë“œ**
    
    **ğŸ“‹ ì§€ì†ì  ì§€ì› ë°©ì•ˆ:**
    1. **í˜„ì¬ ìƒíƒœ ìœ ì§€ ê²©ë ¤**
    2. **ë„ì „ì  ê³¼ì œ ì œê³µ**
    3. **ë¦¬ë”ì‹­ ê°œë°œ ê¸°íšŒ**
    4. **í›„ë°° ë©˜í† ë§ ì°¸ì—¬**
    5. **ìš°ìˆ˜ ì‚¬ë¡€ ê³µìœ **
    
    **ğŸ¯ ì—­í•  ëª¨ë¸:**
    - ë‹¤ë¥¸ í•™ìƒë“¤ì˜ ë¡¤ëª¨ë¸ ì—­í• 
    - í•™ìŠµ ê³µë™ì²´ í™œì„±í™” ê¸°ì—¬
    - ê¸ì •ì  í•™ìŠµ ë¬¸í™” ì¡°ì„±
    """)

def generate_individual_report(student_data: pd.Series, risk_level: str):
    """ê°œë³„ í•™ìƒ ìƒì„¸ ë ˆí¬íŠ¸ ìƒì„±"""
    st.markdown("---")
    st.markdown(f"## ğŸ“‹ **{student_data['ì´ë¦„']} í•™ìƒ ìƒì„¸ ë¶„ì„ ë ˆí¬íŠ¸**")
    
    # Basic information
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown(f"""
        ### ğŸ‘¤ **ê¸°ë³¸ ì •ë³´**
        - **í•™ë²ˆ**: {student_data['í•™ë²ˆ']}
        - **ì´ë¦„**: {student_data['ì´ë¦„']}
        - **í•™ê³¼**: {student_data['í•™ê³¼']}
        - **í•™ë…„**: {student_data['í•™ë…„']}í•™ë…„
        """)
    
    with col2:
        st.markdown(f"""
        ### ğŸ“Š **ìœ„í—˜ë„ í‰ê°€**
        - **ìœ„í—˜ì ìˆ˜**: {student_data['ìœ„í—˜_ì ìˆ˜']:.3f}
        - **ìœ„í—˜ë“±ê¸‰**: {RISK_LEVELS[risk_level]['label']}
        - **ì§ì „í•™ê¸° í‰ì **: {student_data['ì§ì „í•™ê¸°_í‰ì ']:.1f}
        - **í‰ê·  ì¶œì„ë¥ **: {student_data['í‰ê· _ì¶œì„ë¥ ']:.1f}%
        """)
    
    # Risk factor analysis
    st.markdown("### ğŸ” **ìœ„í—˜ ìš”ì¸ ìƒì„¸ ë¶„ì„**")
    
    risk_factors = student_data['ìœ„ê¸°_ìš”ì¸'].split(' | ')
    if risk_factors != ["ìœ„í—˜ ìš”ì¸ ì—†ìŒ"]:
        for i, factor in enumerate(risk_factors, 1):
            st.markdown(f"**{i}. {factor}**")
            
            # Provide specific guidance for each risk factor
            if "í•™ì  ë¶€ì¡±" in factor:
                st.markdown("""
                - **ì›ì¸**: í•™ìŠµ ëŠ¥ë ¥ ë¶€ì¡±, í•™ìŠµ ë™ê¸° ì €í•˜, ìˆ˜ì—… ì´í•´ë„ ë¶€ì¡±
                - **ëŒ€ì‘ë°©ì•ˆ**: ê°œë³„ íŠœí„°ë§, í•™ìŠµë²• êµìœ¡, ê¸°ì´ˆ í•™ë ¥ ë³´ê°•
                - **ëª©í‘œ**: ë‹¤ìŒ í•™ê¸° í‰ì  2.5 ì´ìƒ ë‹¬ì„±
                """)
            elif "ì¶œì„ë¥  ë¶€ì¡±" in factor:
                st.markdown("""
                - **ì›ì¸**: í•™ìŠµ ë™ê¸° ë¶€ì¡±, ê°œì¸ì  ë¬¸ì œ, ì‹œê°„ ê´€ë¦¬ ë¶€ì¡±
                - **ëŒ€ì‘ë°©ì•ˆ**: ì¶œì„ ì²´í¬ ì‹œìŠ¤í…œ, ë™ê¸° ë¶€ì—¬ ìƒë‹´, ì‹œê°„ ê´€ë¦¬ êµìœ¡
                - **ëª©í‘œ**: ì¶œì„ë¥  80% ì´ìƒ ë‹¬ì„±
                """)
            elif "ë“±ë¡ê¸ˆ" in factor:
                st.markdown("""
                - **ì›ì¸**: ê²½ì œì  ì–´ë ¤ì›€, ì¥í•™ê¸ˆ ì •ë³´ ë¶€ì¡±
                - **ëŒ€ì‘ë°©ì•ˆ**: ì¥í•™ê¸ˆ ì•ˆë‚´, í•™ìê¸ˆ ëŒ€ì¶œ ìƒë‹´, ì•„ë¥´ë°”ì´íŠ¸ ì •ë³´ ì œê³µ
                - **ëª©í‘œ**: ë“±ë¡ê¸ˆ ë‚©ë¶€ ì™„ë£Œ ë° ê²½ì œì  ë¶€ë‹´ ì™„í™”
                """)
            elif "ìƒë‹´ ë¶€ì¡±" in factor:
                st.markdown("""
                - **ì›ì¸**: ìƒë‹´ í•„ìš”ì„± ì¸ì‹ ë¶€ì¡±, ì ‘ê·¼ì„± ë¬¸ì œ
                - **ëŒ€ì‘ë°©ì•ˆ**: ì •ê¸° ìƒë‹´ ì¼ì • ìˆ˜ë¦½, ìƒë‹´ ì ‘ê·¼ì„± ê°œì„ 
                - **ëª©í‘œ**: ì›” 1íšŒ ì´ìƒ ì •ê¸° ìƒë‹´ ì‹¤ì‹œ
                """)
    else:
        st.success("í˜„ì¬ íŠ¹ë³„í•œ ìœ„í—˜ ìš”ì¸ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    # Recommendations
    st.markdown("### ğŸ¯ **ë§ì¶¤í˜• ì§€ì› ê³„íš**")
    
    if risk_level == 'high':
        st.markdown("""
        **ğŸš¨ ê¸´ê¸‰ ê°œì… ê³„íš:**
        1. **1ì£¼ ì´ë‚´**: ê¸´ê¸‰ ë©´ë‹´ ì‹¤ì‹œ ë° í˜„í™© íŒŒì•…
        2. **2ì£¼ ì´ë‚´**: ê°œë³„ í•™ìŠµê³„íš ìˆ˜ë¦½ ë° ë©˜í†  ë°°ì •
        3. **1ê°œì›” ì´ë‚´**: ê°€ì¡± ìƒë‹´ ë° ì „ë¬¸ê°€ ì—°ê³„
        4. **ì§€ì†ì **: ì£¼ 1íšŒ ëª¨ë‹ˆí„°ë§ ë° ì§€ì›
        
        **ğŸ“ ì—°ë½ì²˜**: í•™ìƒìƒë‹´ì„¼í„° (ë‚´ì„  1234)
        **ë‹´ë‹¹ì**: ê¹€ìƒë‹´ ìƒë‹´ì‚¬
        """)
    elif risk_level == 'medium':
        st.markdown("""
        **âš ï¸ ì˜ˆë°©ì  ì§€ì› ê³„íš:**
        1. **2ì£¼ ì´ë‚´**: ìƒë‹´ ë° í•™ìŠµ ë™ê¸° ë¶€ì—¬
        2. **1ê°œì›” ì´ë‚´**: ìŠ¤í„°ë”” ê·¸ë£¹ ì—°ê²°
        3. **í•™ê¸° ì¤‘**: 2ì£¼ë§ˆë‹¤ ì •ê¸° ëª¨ë‹ˆí„°ë§
        4. **í•„ìš”ì‹œ**: ì¶”ê°€ ì§€ì› í”„ë¡œê·¸ë¨ ì—°ê³„
        """)
    
    # Progress tracking
    st.markdown("### ğŸ“ˆ **ì§„í–‰ ìƒí™© ì¶”ì **")
    
    progress_data = {
        'í•­ëª©': ['í•™ì  ê°œì„ ', 'ì¶œì„ë¥  í–¥ìƒ', 'ìƒë‹´ ì°¸ì—¬', 'ì „ë°˜ì  ì ì‘'],
        'í˜„ì¬ ìƒíƒœ': ['ì£¼ì˜ í•„ìš”', 'ê°œì„  ì¤‘', 'ì‹œì‘ ë‹¨ê³„', 'ê´€ì°° ì¤‘'],
        'ëª©í‘œ': ['2.5 ì´ìƒ', '80% ì´ìƒ', 'ì›” 1íšŒ', 'ì•ˆì •ì  ì ì‘'],
        'ì§„í–‰ë¥ ': [30, 60, 20, 40]
    }
    
    progress_df = pd.DataFrame(progress_data)
    st.dataframe(progress_df, hide_index=True)
    
    # Action items for advisors
    st.markdown("### ğŸ“ **ì§€ë„êµìˆ˜/ë‹´ë‹¹ì ì²´í¬ë¦¬ìŠ¤íŠ¸**")
    
    checklist = [
        "â–¡ í•™ìƒê³¼ì˜ ê°œë³„ ë©´ë‹´ ì‹¤ì‹œ",
        "â–¡ í•™ìŠµ ê³„íš ìˆ˜ë¦½ ë° ì ê²€",
        "â–¡ ê°€ì¡±/ë³´í˜¸ì ì—°ë½ ë° ìƒí™© ê³µìœ ",
        "â–¡ ê´€ë ¨ ë¶€ì„œ(ìƒë‹´ì„¼í„°, í•™ìŠµì§€ì›ì„¼í„°) ì—°ê³„",
        "â–¡ ì •ê¸°ì  ëª¨ë‹ˆí„°ë§ ì¼ì • ìˆ˜ë¦½",
        "â–¡ ë™ë£Œ í•™ìƒë“¤ê³¼ì˜ ê´€ê³„ ê°œì„  ì§€ì›",
        "â–¡ ì§„ë¡œ ìƒë‹´ ë° ë™ê¸° ë¶€ì—¬",
        "â–¡ ë‹¤ìŒ ë©´ë‹´ ì¼ì • ì˜ˆì•½"
    ]
    
    for item in checklist:
        st.markdown(item)
    
    # Report generation date
    from datetime import datetime
    st.markdown(f"""
    ---
    **ğŸ“… ë ˆí¬íŠ¸ ìƒì„±ì¼**: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M')}  
    **ğŸ“Š ì‹œìŠ¤í…œ**: ë™ëª…ëŒ€í•™êµ ìƒì¡´ë¶„ì„ ê¸°ë°˜ ìœ„ê¸° í•™ìƒ ê´€ë¦¬ ì‹œìŠ¤í…œ  
    **ğŸ”¬ ë¶„ì„ ë°©ë²•**: ìƒì¡´ë¶„ì„ ê¸°ë°˜ ìœ„í—˜ ì˜ˆì¸¡
    """)

def render_department_filter(df: pd.DataFrame) -> str:
    """
    Render department filter and return selected department
    """
    if df.empty:
        return "ì „ì²´"
    
    # Handle NaN values and ensure all values are strings
    unique_depts = df['í•™ê³¼'].dropna().unique()
    unique_depts = [str(dept) for dept in unique_depts if pd.notna(dept)]
    departments = ["ì „ì²´"] + sorted(unique_depts)
    
    selected_department = st.selectbox(
        UI_CONFIG['sections']['department_filter'],
        departments,
        index=0,
        help=MESSAGES['info']['department_filter_help']
    )
    
    return selected_department

def create_sample_survival_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    Create sample survival data for testing survival analysis functions
    ìƒì¡´ë¶„ì„ í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë°ì´í„° ìƒì„±
    """
    if df.empty:
        return df
        
    df_survival = df.copy()
    
    # Generate synthetic survival data based on risk scores
    np.random.seed(42)  # For reproducible results
    
    # Calculate duration (months until dropout or end of observation)
    # Higher risk students tend to drop out earlier
    base_duration = 24  # 24 months base observation period
    
    durations = []
    events = []
    
    for _, row in df_survival.iterrows():
        risk_score = row.get('ìœ„í—˜_ì ìˆ˜', 0.5)
        
        # Higher risk = shorter expected duration
        expected_duration = base_duration * (1 - risk_score * 0.7)
        
        # Add some randomness
        actual_duration = np.random.exponential(expected_duration)
        actual_duration = max(1, min(actual_duration, base_duration))  # Clamp between 1 and 24 months
        
        # Determine if event (dropout) occurred
        # Higher risk students more likely to have event
        event_prob = risk_score * 0.8  # Max 80% chance of dropout
        event_occurred = np.random.random() < event_prob
        
        durations.append(actual_duration)
        events.append(1 if event_occurred else 0)
    
    df_survival['ê´€ì°°ê¸°ê°„_ê°œì›”'] = durations
    df_survival['ì¤‘ë„íƒˆë½ì—¬ë¶€'] = events
    
    return df_survival

def test_survival_analysis_functions():
    """
    Test the survival analysis statistical functions
    ìƒì¡´ë¶„ì„ í†µê³„ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸
    """
    st.subheader("ğŸ§ª ìƒì¡´ë¶„ì„ í†µê³„ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸")
    
    st.info("""
    **ğŸ“Š ìƒì¡´ë¶„ì„ í•µì‹¬ í•¨ìˆ˜ë“¤ì˜ ì •í™•ì„±ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ê²€ì¦í•©ë‹ˆë‹¤**
    
    âœ… **í…ŒìŠ¤íŠ¸ í•­ëª©:**
    â€¢ `calculate_survival_curve()` - ìƒì¡´ê³¡ì„  ê³„ì‚°
    â€¢ `perform_log_rank_test()` - ê·¸ë£¹ ê°„ ì°¨ì´ ê²€ì • (p-value)
    â€¢ `calculate_survival_statistics()` - ì¤‘ì•™ìƒì¡´ì‹œê°„, ì‹ ë¢°êµ¬ê°„ ê³„ì‚°
    â€¢ `get_median_survival_time()` - 50% ìƒì¡´í™•ë¥  ë„ë‹¬ ì‹œì 
    
    ğŸ“ˆ **ì‹¤ì œ ì˜ë£Œ/ë³´í—˜ ë¶„ì•¼ì—ì„œ ê²€ì¦ëœ í†µê³„ ë°©ë²•ë¡ ì„ í•™ìƒ ì¤‘ë„íƒˆë½ ì˜ˆì¸¡ì— ì ìš©**
    """)
    
    # Create sample data for testing
    sample_data = {
        'í•™ë²ˆ': ['2021001', '2021002', '2021003', '2021004', '2021005'],
        'ì´ë¦„': ['ê¹€ì² ìˆ˜', 'ì´ì˜í¬', 'ë°•ë¯¼ìˆ˜', 'ìµœì§€ì˜', 'ì •í˜„ìš°'],
        'í•™ê³¼': ['ì»´í“¨í„°ê³µí•™ê³¼', 'ê²½ì˜í•™ê³¼', 'ì»´í“¨í„°ê³µí•™ê³¼', 'ê²½ì˜í•™ê³¼', 'ì»´í“¨í„°ê³µí•™ê³¼'],
        'í•™ë…„': [2, 3, 1, 4, 2],
        'ìœ„í—˜_ì ìˆ˜': [0.8, 0.3, 0.6, 0.2, 0.9]
    }
    
    test_df = pd.DataFrame(sample_data)
    test_df_with_survival = create_sample_survival_data(test_df)
    
    st.write("**ìƒ˜í”Œ ë°ì´í„°:**")
    st.dataframe(test_df_with_survival[['í•™ë²ˆ', 'ì´ë¦„', 'í•™ê³¼', 'ìœ„í—˜_ì ìˆ˜', 'ê´€ì°°ê¸°ê°„_ê°œì›”', 'ì¤‘ë„íƒˆë½ì—¬ë¶€']])
    
    # Test survival curve calculation
    st.write("**ìƒì¡´ê³¡ì„  ê³„ì‚° í…ŒìŠ¤íŠ¸:**")
    
    try:
        # Calculate overall survival curve
        overall_curve = calculate_kaplan_meier_curve(
            test_df_with_survival, 
            'ê´€ì°°ê¸°ê°„_ê°œì›”', 
            'ì¤‘ë„íƒˆë½ì—¬ë¶€'
        )
        
        if overall_curve:
            st.success("âœ… ì „ì²´ ìƒì¡´ê³¡ì„  ê³„ì‚° ì„±ê³µ")
            st.write(f"- ì¤‘ì•™ìƒì¡´ì‹œê°„: {overall_curve.median_survival_time:.2f}ê°œì›”" if overall_curve.median_survival_time else "- ì¤‘ì•™ìƒì¡´ì‹œê°„: ê´€ì°°ê¸°ê°„ ë‚´ ë¯¸ë„ë‹¬")
            st.write(f"- ì‹œê°„ í¬ì¸íŠ¸ ìˆ˜: {len(overall_curve.time_points)}")
            st.write(f"- ì‹ ë¢°êµ¬ê°„ ê³„ì‚°: {'ì„±ê³µ' if overall_curve.confidence_lower else 'ì‹¤íŒ¨'}")
        else:
            st.error("âŒ ì „ì²´ ìƒì¡´ê³¡ì„  ê³„ì‚° ì‹¤íŒ¨")
            
        # Test group-based survival curves
        dept_curves = []
        for dept in test_df_with_survival['í•™ê³¼'].unique():
            curve = calculate_kaplan_meier_curve(
                test_df_with_survival,
                'ê´€ì°°ê¸°ê°„_ê°œì›”',
                'ì¤‘ë„íƒˆë½ì—¬ë¶€',
                group_by='í•™ê³¼',
                group_value=dept
            )
            if curve:
                dept_curves.append(curve)
        
        if dept_curves:
            st.success(f"âœ… í•™ê³¼ë³„ ìƒì¡´ê³¡ì„  ê³„ì‚° ì„±ê³µ ({len(dept_curves)}ê°œ í•™ê³¼)")
            for curve in dept_curves:
                median_text = f"{curve.median_survival_time:.2f}ê°œì›”" if curve.median_survival_time else "ë¯¸ë„ë‹¬"
                st.write(f"- {curve.group_name}: ì¤‘ì•™ìƒì¡´ì‹œê°„ {median_text}")
        else:
            st.error("âŒ í•™ê³¼ë³„ ìƒì¡´ê³¡ì„  ê³„ì‚° ì‹¤íŒ¨")
            
        # Test log-rank test
        st.write("**ë¡œê·¸ë­í¬ ê²€ì • í…ŒìŠ¤íŠ¸:**")
        p_value = perform_log_rank_test(
            test_df_with_survival,
            'ê´€ì°°ê¸°ê°„_ê°œì›”',
            'ì¤‘ë„íƒˆë½ì—¬ë¶€',
            'í•™ê³¼'
        )
        
        if p_value is not None:
            st.success(f"âœ… ë¡œê·¸ë­í¬ ê²€ì • ì„±ê³µ: p-value = {p_value:.4f}")
            significance = "í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•¨" if p_value < 0.05 else "í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ì§€ ì•ŠìŒ"
            st.write(f"- í•™ê³¼ ê°„ ìƒì¡´ê³¡ì„  ì°¨ì´: {significance}")
        else:
            st.error("âŒ ë¡œê·¸ë­í¬ ê²€ì • ì‹¤íŒ¨")
            
        # Test survival statistics calculation
        st.write("**ìƒì¡´ë¶„ì„ í†µê³„ ê³„ì‚° í…ŒìŠ¤íŠ¸:**")
        if dept_curves:
            stats = calculate_survival_statistics(dept_curves)
            if stats:
                st.success("âœ… ìƒì¡´ë¶„ì„ í†µê³„ ê³„ì‚° ì„±ê³µ")
                for group_name, group_stats in stats.items():
                    st.write(f"**{group_name}:**")
                    for stat_name, stat_value in group_stats.items():
                        if stat_value is not None:
                            if 'survival_at' in stat_name:
                                st.write(f"  - {stat_name}: {stat_value:.3f}")
                            elif 'median' in stat_name:
                                st.write(f"  - {stat_name}: {stat_value:.2f}ê°œì›”")
                            else:
                                st.write(f"  - {stat_name}: {stat_value:.3f}")
            else:
                st.error("âŒ ìƒì¡´ë¶„ì„ í†µê³„ ê³„ì‚° ì‹¤íŒ¨")
                
    except Exception as e:
        st.error(f"âŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

def render_variable_analysis(df: pd.DataFrame, variable: str):
    """
    Render analysis for a specific variable
    """
    if df.empty or variable == "ì „ì²´":
        return
    
    st.subheader(f"ğŸ” {variable} ë³€ìˆ˜ë³„ ìœ„í—˜ ë¶„ì„")
    
    # Check if variable exists in dataframe
    if variable not in df.columns:
        st.warning(f"'{variable}' ë³€ìˆ˜ê°€ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤. ì „ì²´ ëŒ€ì‹œë³´ë“œë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.")
        return
    
    # Get unique values for the variable (handle NaN and mixed types)
    unique_values = df[variable].dropna().unique()
    unique_values = [val for val in unique_values if pd.notna(val)]
    
    if len(unique_values) == 0:
        st.warning(f"'{variable}' ë³€ìˆ˜ì— ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # Create tabs for each unique value
    if len(unique_values) <= 6:  # If not too many values, create tabs
        tabs = st.tabs([f"{variable}: {val}" for val in unique_values])
        
        for i, value in enumerate(unique_values):
            with tabs[i]:
                render_variable_group_analysis(df, variable, value)
    else:
        # If too many values, use selectbox
        selected_value = st.selectbox(f"{variable} ê°’ì„ ì„ íƒí•˜ì„¸ìš”:", unique_values)
        render_variable_group_analysis(df, variable, selected_value)

def render_variable_group_analysis(df: pd.DataFrame, variable: str, value):
    """
    Render analysis for a specific group within a variable
    """
    # Filter data for the specific group
    group_df = df[df[variable] == value].copy()
    
    if group_df.empty:
        st.warning(f"{variable} = {value} ê·¸ë£¹ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # Calculate group metrics
    total_students = len(group_df)
    risk_counts = group_df['ìœ„í—˜_ë ˆë²¨'].value_counts()
    avg_risk_score = group_df['ìœ„í—˜_ì ìˆ˜'].mean()
    
    # Display group summary
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ì´ í•™ìƒ ìˆ˜", f"{total_students}ëª…")
    
    with col2:
        high_risk = risk_counts.get('high', 0)
        high_risk_pct = (high_risk / total_students * 100) if total_students > 0 else 0
        st.metric("ê³ ìœ„í—˜ í•™ìƒ", f"{high_risk}ëª…", f"{high_risk_pct:.1f}%")
    
    with col3:
        medium_risk = risk_counts.get('medium', 0)
        medium_risk_pct = (medium_risk / total_students * 100) if total_students > 0 else 0
        st.metric("ì¤‘ìœ„í—˜ í•™ìƒ", f"{medium_risk}ëª…", f"{medium_risk_pct:.1f}%")
    
    with col4:
        st.metric("í‰ê·  ìœ„í—˜ì ìˆ˜", f"{avg_risk_score:.3f}")
    
    # Risk distribution for this group
    col1, col2 = st.columns(2)
    
    with col1:
        # Risk level pie chart
        if not risk_counts.empty:
            colors = [RISK_LEVELS[level]['color'] for level in risk_counts.index if level in RISK_LEVELS]
            labels = [RISK_LEVELS[level]['label'] for level in risk_counts.index if level in RISK_LEVELS]
            
            fig_pie = go.Figure(data=[go.Pie(
                labels=labels,
                values=risk_counts.values,
                marker_colors=colors,
                textinfo='label+percent',
                textfont_size=12
            )])
            fig_pie.update_layout(
                title=f"{variable} = {value} ìœ„í—˜ë„ ë¶„í¬",
                height=400
            )
            st.plotly_chart(fig_pie, width='stretch')
    
    with col2:
        # Risk score histogram
        fig_hist = px.histogram(
            group_df, 
            x='ìœ„í—˜_ì ìˆ˜', 
            nbins=15,
            title=f"{variable} = {value} ìœ„í—˜ì ìˆ˜ ë¶„í¬",
            labels={'ìœ„í—˜_ì ìˆ˜': 'ìœ„í—˜ ì ìˆ˜', 'count': 'í•™ìƒ ìˆ˜'}
        )
        fig_hist.update_layout(height=400)
        st.plotly_chart(fig_hist, width='stretch')
    
    # Detailed student list
    st.markdown("### ğŸ“‹ ìƒì„¸ í•™ìƒ ëª©ë¡")
    
    # Risk level filter
    risk_filter = st.selectbox(
        "ìœ„í—˜ë„ í•„í„°:",
        ["ì „ì²´", "ê³ ìœ„í—˜", "ì¤‘ìœ„í—˜", "ì €ìœ„í—˜", "ì•ˆì „"],
        key=f"risk_filter_{variable}_{value}"
    )
    
    if risk_filter != "ì „ì²´":
        risk_map = {"ê³ ìœ„í—˜": "high", "ì¤‘ìœ„í—˜": "medium", "ì €ìœ„í—˜": "low", "ì•ˆì „": "safe"}
        filtered_df = group_df[group_df['ìœ„í—˜_ë ˆë²¨'] == risk_map[risk_filter]]
    else:
        filtered_df = group_df
    
    if not filtered_df.empty:
        # Display student table
        display_columns = ['í•™ë²ˆ', 'ì´ë¦„', 'í•™ê³¼', 'í•™ë…„', 'ìœ„í—˜_ì ìˆ˜', 'ìœ„í—˜_ë ˆë²¨', 'ì§ì „í•™ê¸°_í‰ì ', 'í‰ê· _ì¶œì„ë¥ ']
        if 'ìœ„ê¸°_ìš”ì¸' in filtered_df.columns:
            display_columns.append('ìœ„ê¸°_ìš”ì¸')
        
        display_df = filtered_df[display_columns].copy()
        display_df = display_df.sort_values('ìœ„í—˜_ì ìˆ˜', ascending=False)
        
        st.dataframe(
            display_df,
            width='stretch',
            hide_index=True,
            column_config={
                "í•™ë²ˆ": st.column_config.TextColumn("í•™ë²ˆ", width="small"),
                "ì´ë¦„": st.column_config.TextColumn("ì´ë¦„", width="small"),
                "í•™ê³¼": st.column_config.TextColumn("í•™ê³¼", width="medium"),
                "í•™ë…„": st.column_config.NumberColumn("í•™ë…„", width="small"),
                "ìœ„í—˜_ì ìˆ˜": st.column_config.NumberColumn("ìœ„í—˜ì ìˆ˜", format="%.3f", width="small"),
                "ìœ„í—˜_ë ˆë²¨": st.column_config.TextColumn("ìœ„í—˜ë„", width="small"),
                "ì§ì „í•™ê¸°_í‰ì ": st.column_config.NumberColumn("í‰ì ", format="%.1f", width="small"),
                "í‰ê· _ì¶œì„ë¥ ": st.column_config.NumberColumn("ì¶œì„ë¥ ", format="%.1f%%", width="small"),
                "ìœ„ê¸°_ìš”ì¸": st.column_config.TextColumn("ìœ„ê¸° ìš”ì¸", width="large")
            }
        )
        
        st.info(f"ğŸ“Š {risk_filter} í•™ìƒ: {len(filtered_df)}ëª… / ì „ì²´ {total_students}ëª…")
    else:
        st.info(f"{risk_filter} í•™ìƒì´ ì—†ìŠµë‹ˆë‹¤.")

def main():
    """
    Main application function
    """
    render_header()
    
    # Add methodology information panel in sidebar
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ“Š ë¶„ì„ ë°©ë²•ë¡ ")
    with st.sidebar.expander("ìƒì¡´ë¶„ì„ ë°©ë²•ë¡ ", expanded=False):
        st.markdown("""
        **ğŸ”¬ í•µì‹¬ ê°œë…:**
        - **ìƒì¡´ì‹œê°„**: ì…í•™~ì¤‘ë„íƒˆë½ ê¸°ê°„
        - **ê²€ì—´(Censoring)**: ê´€ì°° ì¢…ë£Œì‹œì ê¹Œì§€ ì¬í•™ì¤‘ì¸ í•™ìƒ
        - **ìœ„í—˜í•¨ìˆ˜**: íŠ¹ì • ì‹œì ì—ì„œì˜ ì¤‘ë„íƒˆë½ ìœ„í—˜ë„
        
        **ğŸ“ˆ ì¥ì :**
        - ë¶ˆì™„ì „í•œ ê´€ì°° ë°ì´í„° ì²˜ë¦¬ ê°€ëŠ¥
        - ì‹œê°„ì— ë”°ë¥¸ ìœ„í—˜ë„ ë³€í™” ì¶”ì 
        - ê·¸ë£¹ ê°„ í†µê³„ì  ë¹„êµ ê°€ëŠ¥
        
        **ğŸ¯ ì ìš© ë¶„ì•¼:**
        - ì˜í•™: í™˜ì ìƒì¡´ìœ¨ ë¶„ì„
        - ê³µí•™: ì œí’ˆ ìˆ˜ëª… ë¶„ì„  
        - êµìœ¡: í•™ìƒ ì”ì¡´ìœ¨ ë¶„ì„
        """)
    
    # Add test section for survival analysis functions
    if st.sidebar.checkbox("ìƒì¡´ë¶„ì„ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ ëª¨ë“œ", value=False):
        test_survival_analysis_functions()
        st.markdown("---")
    
    # Add variable-specific analysis menu
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ” ë³€ìˆ˜ë³„ ìœ„í—˜ ë¶„ì„")
    
    analysis_options = {
        "ì „ì²´ ëŒ€ì‹œë³´ë“œ": "ì „ì²´",
        "ë‹¤ì „ê³µì‹ ì²­ë³„ ë¶„ì„": "ë‹¤ì „ê³µì‹ ì²­", 
        "ëª¨ë“ˆì‹ ì²­ë³„ ë¶„ì„": "ëª¨ë“ˆì‹ ì²­",
        "ë¹„êµê³¼ì°¸ì—¬ë³„ ë¶„ì„": "ë¹„êµê³¼ì°¸ì—¬íšŸìˆ˜",
        "ì¥í•™ê¸ˆì‹ ì²­ë³„ ë¶„ì„": "ì¥í•™ê¸ˆ_ì‹ ì²­",
        "ë“±ë¡ê¸ˆë‚©ë¶€ë³„ ë¶„ì„": "ë“±ë¡ê¸ˆ_ë‚©ë¶€_ìƒíƒœ",
        "í•™ê³¼ë³„ ë¶„ì„": "í•™ê³¼",
        "í•™ë…„ë³„ ë¶„ì„": "í•™ë…„"
    }
    
    selected_analysis = st.sidebar.selectbox(
        "ë¶„ì„í•  ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
        list(analysis_options.keys()),
        index=0
    )
    
    analysis_variable = analysis_options[selected_analysis]
    
    # Load data - try primary file first, then backup
    df = load_student_data(DATA_CONFIG['primary_file'])
    if df.empty and os.path.exists(DATA_CONFIG['backup_file']):
        st.info(MESSAGES['info']['using_sample_data'])
        df = load_student_data(DATA_CONFIG['backup_file'])
    
    if df.empty:
        st.stop()
    
    # Calculate survival risk scores
    df_with_risk = calculate_survival_risk_score(df)
    
    # Calculate metrics
    metrics = calculate_summary_metrics(df_with_risk)
    
    # Show different content based on selected analysis
    if analysis_variable == "ì „ì²´":
        # Show full dashboard
        # Render survival metrics
        render_survival_metrics(metrics)
        
        st.markdown("---")
        
        # Render risk distribution and analysis
        col1, col2 = st.columns(2)
        with col1:
            render_risk_distribution(df_with_risk)
        with col2:
            render_risk_factors_analysis(df_with_risk)
        
        st.markdown("---")
        
        # Render survival curves
        render_survival_curves(df_with_risk)
        
        st.markdown("---")
        
        # Department filter
        selected_department = render_department_filter(df_with_risk)
        
        st.markdown("---")
        
        # Render students by risk level
        risk_tabs = st.tabs([
            RISK_LEVELS['high']['label'],
            RISK_LEVELS['medium']['label'], 
            RISK_LEVELS['low']['label'],
            RISK_LEVELS['safe']['label']
        ])
        
        with risk_tabs[0]:
            render_risk_students(df_with_risk, 'high', selected_department)
        
        with risk_tabs[1]:
            render_risk_students(df_with_risk, 'medium', selected_department)
        
        with risk_tabs[2]:
            render_risk_students(df_with_risk, 'low', selected_department)
        
        with risk_tabs[3]:
            render_risk_students(df_with_risk, 'safe', selected_department)
    
    else:
        # Show variable-specific analysis
        render_variable_analysis(df_with_risk, analysis_variable)
    
    # Footer
    st.markdown("---")
    st.markdown(
        f"""
        <div style='text-align: center; color: #666; font-size: 0.8em;'>
        {DEVELOPER_INFO['description']} v{DEVELOPER_INFO['version']} | 
        ìƒì¡´ë¶„ì„ ê¸°ë°˜ ìœ„í—˜ë„ ì˜ˆì¸¡ ì‹œìŠ¤í…œ | 
        ê³ ìœ„í—˜: {SURVIVAL_CRITERIA['high_risk_threshold']:.1f}+ | 
        ì¤‘ìœ„í—˜: {SURVIVAL_CRITERIA['medium_risk_threshold']:.1f}-{SURVIVAL_CRITERIA['high_risk_threshold']:.1f} | 
        ì €ìœ„í—˜: {SURVIVAL_CRITERIA['low_risk_threshold']:.1f}-{SURVIVAL_CRITERIA['medium_risk_threshold']:.1f}
        </div>
        """, 
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()